{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bbb6f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1024, 128)         512       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1024, 128)        512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 512, 128)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512, 128)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 512, 128)          49280     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 256, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256, 128)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256, 256)         263168    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256, 256)          0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 486,722\n",
      "Trainable params: 486,210\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.layers import LSTM, Bidirectional, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Embedding, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "# Now load the model\n",
    "model = load_model(\"model 1.h5\")\n",
    "\n",
    "# You can print a summary to check if it works\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "263eff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      "🧬 Prediction: Therapeutic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# === Load model and scaler ===\n",
    "model = load_model('model 1.h5')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# === Load ProtBERT model ===\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "bert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "\n",
    "# === ProtBERT Preprocessing ===\n",
    "def embed_with_protbert(sequence: str) -> np.ndarray:\n",
    "    # Add spaces between amino acids\n",
    "    spaced_seq = ' '.join(sequence)\n",
    "    encoded_input = tokenizer(spaced_seq, return_tensors='pt', padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**encoded_input)\n",
    "    \n",
    "    # Take mean across all token embeddings (excluding [CLS], [SEP])\n",
    "    embeddings = outputs.last_hidden_state.squeeze(0)[1:-1].mean(dim=0)\n",
    "    return embeddings.cpu().numpy().reshape(1, -1)  # shape (1, 1024)\n",
    "\n",
    "# === Predict function ===\n",
    "def predict_therapeutic(sequence: str):\n",
    "    embedded = embed_with_protbert(sequence)\n",
    "    scaled_input = scaler.transform(embedded)\n",
    "    scaled_input = scaled_input.reshape(1, 1024, 1)  # match model input shape\n",
    "\n",
    "    prediction = model.predict(scaled_input)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "    return \"Therapeutic\" if predicted_class == 1 else \"Non-Therapeutic\"\n",
    "\n",
    "# === Main Driver ===\n",
    "if __name__ == \"__main__\":\n",
    "    user_seq = input(\"Enter your peptide sequence: \").strip().upper()\n",
    "    result = predict_therapeutic(user_seq)\n",
    "    print(f\"\\n🧬 Prediction: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8596723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 48, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 24, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,480\n",
      "Trainable params: 25,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.layers import LSTM, Bidirectional, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Embedding, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "# Now load the model\n",
    "model = load_model(\"model 2.h5\")\n",
    "\n",
    "# You can print a summary to check if it works\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dce9aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 265ms/step\n",
      "\n",
      "🧬 Model 2 Prediction: Anti Fungal Peptide\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "# Load Model 2\n",
    "model = tf.keras.models.load_model(\"model 2.h5\")\n",
    "\n",
    "# Load dependencies with joblib\n",
    "scaler = joblib.load(\"scaler 2.pkl\")\n",
    "pca = joblib.load(\"pca_model.pkl\")\n",
    "\n",
    "# Load label encoder and category mapping\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = joblib.load(f)\n",
    "\n",
    "with open(\"category_mapping.pkl\", \"rb\") as f:\n",
    "    category_mapping = joblib.load(f)\n",
    "\n",
    "# Load ProtBERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "protbert = TFBertModel.from_pretrained(\"Rostlab/prot_bert\", from_pt=True)\n",
    "\n",
    "# 🧬 ProtBERT embedding function\n",
    "def preprocess_protbert(sequence):\n",
    "    formatted_seq = \" \".join(list(sequence.strip().upper()))\n",
    "    tokens = tokenizer([formatted_seq], return_tensors=\"tf\", padding=True)\n",
    "    with tf.device(\"/CPU:0\"):  # Use CPU for compatibility with TF models\n",
    "        output = protbert(**tokens)\n",
    "    embeddings = tf.reduce_mean(output.last_hidden_state, axis=1).numpy()\n",
    "    return embeddings\n",
    "\n",
    "# 🧠 Model 2 Prediction Pipeline\n",
    "def predict_category(sequence: str):\n",
    "    embedding = preprocess_protbert(sequence)\n",
    "\n",
    "    # Apply scaler and PCA\n",
    "    scaled = scaler.transform(embedding)\n",
    "    reduced = pca.transform(scaled)\n",
    "\n",
    "    # Prediction\n",
    "    prediction = model.predict(reduced)\n",
    "    predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "    predicted_category = category_mapping.get(predicted_label, \"Unknown Category\")\n",
    "\n",
    "    return predicted_category\n",
    "\n",
    "# Run the model on user input\n",
    "if __name__ == \"__main__\":\n",
    "    user_seq = input(\"Enter peptide sequence: \").strip().upper()\n",
    "    category_result = predict_category(user_seq)\n",
    "    print(f\"\\n🧬 Model 2 Prediction: {category_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdf48a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗂️ Model keys (groups): ['model_weights', 'optimizer_weights']\n",
      "\n",
      "✅ Found 'model_config'!\n",
      "{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"registered_name\": null}, \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_shape\": [null, 38], \"dtype\": \"float32\", \"sparse\": false, \"name\": \"input_layer\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": {\"module\": \"keras\", \"class_name\": \"DTypePolicy\", \"config\": {\"name\": \"float32\"}, \"reg\n",
      "\n",
      "📋 Layers in model:\n",
      "🔹 dense\n",
      "🔹 dense_1\n",
      "🔹 dense_2\n",
      "🔹 top_level_model_weights\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(\"Model_3.h5\", \"r\") as file:\n",
    "    print(\"🗂️ Model keys (groups):\", list(file.keys()))\n",
    "    \n",
    "    # Check layer configuration (if available)\n",
    "    if \"model_config\" in file.attrs:\n",
    "        print(\"\\n✅ Found 'model_config'!\")\n",
    "        print(file.attrs[\"model_config\"][:500])  # print first 500 chars\n",
    "    else:\n",
    "        print(\"\\n⚠️ No model_config attribute found.\")\n",
    "\n",
    "    # List model layers\n",
    "    print(\"\\n📋 Layers in model:\")\n",
    "    for layer in file[\"model_weights\"].keys():\n",
    "        print(\"🔹\", layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4bda99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Extracted Biological Features:\n",
      "Molecular Weight: 59908.9278\n",
      "Aromaticity: 0.1243\n",
      "Instability Index: 53.0476\n",
      "Isoelectric Point: 8.0923\n",
      "Hydrophobicity (GRAVY): -0.3132\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "\n",
      "🎯 Predicted Biological Score: 656.3642\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "# Load model and scaler\n",
    "model = load_model(\"model 3.h5\")\n",
    "with open(\"scaler 3.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Feature labels\n",
    "feature_names = [\n",
    "    \"Molecular Weight\",\n",
    "    \"Aromaticity\",\n",
    "    \"Instability Index\",\n",
    "    \"Isoelectric Point\",\n",
    "    \"Hydrophobicity (GRAVY)\"\n",
    "]\n",
    "\n",
    "# Function to extract and print features\n",
    "def get_bio_features(sequence):\n",
    "    analyzer = ProteinAnalysis(sequence)\n",
    "    features = [\n",
    "        analyzer.molecular_weight(),\n",
    "        analyzer.aromaticity(),\n",
    "        analyzer.instability_index(),\n",
    "        analyzer.isoelectric_point(),\n",
    "        analyzer.gravy()\n",
    "    ]\n",
    "    return features\n",
    "\n",
    "# Ask user to enter a sequence\n",
    "input_sequence = input(\"🔡 Enter a peptide sequence (only standard amino acids): \").strip().upper()\n",
    "\n",
    "# Validate sequence\n",
    "valid_amino_acids = set(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "if not input_sequence or any(aa not in valid_amino_acids for aa in input_sequence):\n",
    "    print(\"❌ Invalid sequence. Please enter a valid peptide sequence using only standard amino acids (ACDEFGHIKLMNPQRSTVWY).\")\n",
    "else:\n",
    "    # Extract features\n",
    "    features = get_bio_features(input_sequence)\n",
    "\n",
    "    print(\"\\n🔬 Extracted Biological Features:\")\n",
    "    for name, value in zip(feature_names, features):\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "    # Scale and predict\n",
    "    features_scaled = scaler.transform([features])\n",
    "    predicted_score = model.predict(features_scaled)[0][0]\n",
    "\n",
    "    print(f\"\\n🎯 Predicted Biological Score: {predicted_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
