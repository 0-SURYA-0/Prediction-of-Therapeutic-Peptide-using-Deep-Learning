{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2a2135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "TensorFlow version: 2.10.0\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "def load_peptide_data(data_path, max_sequences_per_class=25000):\n",
    "    \"\"\"\n",
    "    Load peptide sequences from CSV files with comprehensive error handling and statistics\n",
    "    \"\"\"\n",
    "    therapeutic_path = os.path.join(data_path, \"Therapeutic data\")\n",
    "    non_therapeutic_path = os.path.join(data_path, \"Non-Therapeutic data\")\n",
    "    \n",
    "    sequences, labels = [], []\n",
    "    file_stats = {}\n",
    "    \n",
    "    if not os.path.exists(therapeutic_path):\n",
    "        print(f\"Warning: {therapeutic_path} not found!\")\n",
    "        return [], [], {}\n",
    "    \n",
    "    if not os.path.exists(non_therapeutic_path):\n",
    "        print(f\"Warning: {non_therapeutic_path} not found!\")\n",
    "        return [], [], {}\n",
    "    \n",
    "    print(\"Loading therapeutic peptides...\")\n",
    "    therapeutic_total = 0\n",
    "    for filename in os.listdir(therapeutic_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(therapeutic_path, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                if df.shape[1] >= 1:\n",
    "                    seqs = df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "                    seqs = [seq.strip().upper() for seq in seqs if seq.strip()]\n",
    "                    \n",
    "                    # Validate and clean sequences\n",
    "                    valid_seqs = []\n",
    "                    for seq in seqs:\n",
    "                        clean_seq = ''.join([c for c in seq if c in 'ACDEFGHIKLMNPQRSTVWY'])\n",
    "                        if 5 <= len(clean_seq) <= 200:\n",
    "                            valid_seqs.append(clean_seq)\n",
    "                    \n",
    "                    # Limit sequences to prevent memory issues\n",
    "                    if max_sequences_per_class and therapeutic_total + len(valid_seqs) > max_sequences_per_class:\n",
    "                        remaining = max(0, max_sequences_per_class - therapeutic_total)\n",
    "                        valid_seqs = valid_seqs[:remaining]\n",
    "                    \n",
    "                    sequences.extend(valid_seqs)\n",
    "                    labels.extend([1] * len(valid_seqs))\n",
    "                    therapeutic_total += len(valid_seqs)\n",
    "                    file_stats[f\"therapeutic_{filename}\"] = len(valid_seqs)\n",
    "                    print(f\"  âœ“ {filename}: {len(valid_seqs)} valid sequences\")\n",
    "                    \n",
    "                    if max_sequences_per_class and therapeutic_total >= max_sequences_per_class:\n",
    "                        break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error reading {filename}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"Total therapeutic sequences: {therapeutic_total}\")\n",
    "    \n",
    "    print(\"\\nLoading non-therapeutic peptides...\")\n",
    "    non_therapeutic_total = 0\n",
    "    for filename in os.listdir(non_therapeutic_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(non_therapeutic_path, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                if df.shape[1] >= 1:\n",
    "                    seqs = df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "                    seqs = [seq.strip().upper() for seq in seqs if seq.strip()]\n",
    "                    \n",
    "                    # Validate and clean sequences\n",
    "                    valid_seqs = []\n",
    "                    for seq in seqs:\n",
    "                        clean_seq = ''.join([c for c in seq if c in 'ACDEFGHIKLMNPQRSTVWY'])\n",
    "                        if 5 <= len(clean_seq) <= 200:\n",
    "                            valid_seqs.append(clean_seq)\n",
    "                    \n",
    "                    # Limit sequences to prevent memory issues\n",
    "                    if max_sequences_per_class and non_therapeutic_total + len(valid_seqs) > max_sequences_per_class:\n",
    "                        remaining = max(0, max_sequences_per_class - non_therapeutic_total)\n",
    "                        valid_seqs = valid_seqs[:remaining]\n",
    "                    \n",
    "                    sequences.extend(valid_seqs)\n",
    "                    labels.extend([0] * len(valid_seqs))\n",
    "                    non_therapeutic_total += len(valid_seqs)\n",
    "                    file_stats[f\"non_therapeutic_{filename}\"] = len(valid_seqs)\n",
    "                    print(f\"  âœ“ {filename}: {len(valid_seqs)} valid sequences\")\n",
    "                    \n",
    "                    if max_sequences_per_class and non_therapeutic_total >= max_sequences_per_class:\n",
    "                        break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error reading {filename}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"Total non-therapeutic sequences: {non_therapeutic_total}\")\n",
    "    print(f\"Overall total: {len(sequences)} sequences\")\n",
    "    \n",
    "    return sequences, labels, file_stats\n",
    "\n",
    "def extract_comprehensive_features(sequences):\n",
    "    \"\"\"\n",
    "    Extract comprehensive biochemical features from peptide sequences\n",
    "    Returns enhanced feature set optimized for alternative model comparison\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    print(\"Extracting comprehensive biochemical features...\")\n",
    "    \n",
    "    for seq in tqdm(sequences, desc=\"Processing sequences\"):\n",
    "        seq_len = len(seq)\n",
    "        feature_vector = []\n",
    "        \n",
    "        # 1. Basic sequence properties\n",
    "        feature_vector.append(seq_len)\n",
    "        \n",
    "        # 2. Amino acid composition (20 features)\n",
    "        aa_composition = {}\n",
    "        for aa in 'ACDEFGHIKLMNPQRSTVWY':\n",
    "            aa_composition[aa] = seq.count(aa) / seq_len\n",
    "            feature_vector.append(aa_composition[aa])\n",
    "        \n",
    "        # 3. Amino acid group compositions\n",
    "        hydrophobic = sum(seq.count(aa) for aa in 'AILMFWV') / seq_len\n",
    "        polar = sum(seq.count(aa) for aa in 'NQST') / seq_len\n",
    "        charged = sum(seq.count(aa) for aa in 'KRDEH') / seq_len\n",
    "        aromatic = sum(seq.count(aa) for aa in 'FWY') / seq_len\n",
    "        tiny = sum(seq.count(aa) for aa in 'ACSV') / seq_len\n",
    "        small = sum(seq.count(aa) for aa in 'ABDHNT') / seq_len\n",
    "        aliphatic = sum(seq.count(aa) for aa in 'ILV') / seq_len\n",
    "        \n",
    "        feature_vector.extend([hydrophobic, polar, charged, aromatic, tiny, small, aliphatic])\n",
    "        \n",
    "        # 4. Charge properties\n",
    "        positive_charge = seq.count('K') + seq.count('R') + seq.count('H')\n",
    "        negative_charge = seq.count('D') + seq.count('E')\n",
    "        net_charge = positive_charge - negative_charge\n",
    "        \n",
    "        feature_vector.extend([\n",
    "            positive_charge / seq_len,\n",
    "            negative_charge / seq_len,\n",
    "            net_charge / seq_len,\n",
    "            abs(net_charge) / seq_len\n",
    "        ])\n",
    "        \n",
    "        # 5. Structural features\n",
    "        proline_content = seq.count('P') / seq_len\n",
    "        glycine_content = seq.count('G') / seq_len\n",
    "        cysteine_content = seq.count('C') / seq_len\n",
    "        \n",
    "        feature_vector.extend([proline_content, glycine_content, cysteine_content])\n",
    "        \n",
    "        # 6. Dipeptide composition (enhanced)\n",
    "        dipeptide_freq = {}\n",
    "        for i in range(len(seq)-1):\n",
    "            dipeptide = seq[i:i+2]\n",
    "            dipeptide_freq[dipeptide] = dipeptide_freq.get(dipeptide, 0) + 1\n",
    "        \n",
    "        # Top 15 most important dipeptides for therapeutic prediction\n",
    "        important_dipeptides = ['AA', 'AC', 'AG', 'AL', 'AR', 'AS', 'AT', 'AV', 'AY', 'AW',\n",
    "                               'KK', 'RR', 'LL', 'FF', 'WW']\n",
    "        \n",
    "        for dp in important_dipeptides:\n",
    "            feature_vector.append(dipeptide_freq.get(dp, 0) / (seq_len - 1) if seq_len > 1 else 0)\n",
    "        \n",
    "        # 7. Hydrophobic moment (simplified)\n",
    "        hydrophobic_values = {\n",
    "            'A': 1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5,\n",
    "            'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I': 4.5,\n",
    "            'L': 3.8, 'K': -3.9, 'M': 1.9, 'F': 2.8, 'P': -1.6,\n",
    "            'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2\n",
    "        }\n",
    "        \n",
    "        hydrophobic_moment = 0\n",
    "        for i, aa in enumerate(seq):\n",
    "            if aa in hydrophobic_values:\n",
    "                angle = i * 100 * np.pi / 180\n",
    "                hydrophobic_moment += hydrophobic_values[aa] * np.exp(1j * angle)\n",
    "        \n",
    "        feature_vector.append(abs(hydrophobic_moment) / seq_len)\n",
    "        \n",
    "        # 8. Sequence complexity measures\n",
    "        # Repeating patterns\n",
    "        max_repeat = 1\n",
    "        current_repeat = 1\n",
    "        for i in range(1, seq_len):\n",
    "            if seq[i] == seq[i-1]:\n",
    "                current_repeat += 1\n",
    "                max_repeat = max(max_repeat, current_repeat)\n",
    "            else:\n",
    "                current_repeat = 1\n",
    "        \n",
    "        feature_vector.append(max_repeat / seq_len)\n",
    "        \n",
    "        # Entropy (sequence diversity)\n",
    "        entropy = -sum((count/seq_len) * np.log2(count/seq_len) \n",
    "                      for count in aa_composition.values() if count > 0)\n",
    "        feature_vector.append(entropy)\n",
    "        \n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    features_array = np.array(features, dtype=np.float32)\n",
    "    print(f\"Feature extraction completed: {features_array.shape[1]} features per sequence\")\n",
    "    \n",
    "    return features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ecee9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_dense_model(input_dim):\n",
    "    \"\"\"\n",
    "    Create advanced dense neural network with batch normalization and regularization\n",
    "    Optimized for therapeutic peptide prediction\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.15),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        \n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_advanced_conv1d_model(input_dim):\n",
    "    \"\"\"\n",
    "    Create advanced 1D CNN model with enhanced architecture\n",
    "    Optimized for sequence-like feature patterns\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n",
    "        \n",
    "        Conv1D(64, 5, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv1D(32, 3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv1D(16, 3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_lstm_model(input_dim):\n",
    "    \"\"\"\n",
    "    Create LSTM model for sequence-based learning\n",
    "    Optimized with reduced complexity for faster training\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n",
    "        \n",
    "        LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        LSTM(32, dropout=0.2, recurrent_dropout=0.2),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        \n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model_complexity(model):\n",
    "    \"\"\"\n",
    "    Get model complexity information\n",
    "    \"\"\"\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    return {\n",
    "        'total_params': total_params,\n",
    "        'trainable_params': trainable_params,\n",
    "        'non_trainable_params': non_trainable_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e30958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ALTERNATIVE MODEL COMPARISON FOR THERAPEUTIC PEPTIDE PREDICTION ===\n",
      "\n",
      "Loading therapeutic peptides...\n",
      "  âœ“ Anti Bacterial Peptide_trimmed.csv: 6999 valid sequences\n",
      "  âœ“ Anti Cancer Peptide_trimmed.csv: 3999 valid sequences\n",
      "  âœ“ Anti Fungal Peptide_trimmed.csv: 4002 valid sequences\n",
      "Total therapeutic sequences: 15000\n",
      "\n",
      "Loading non-therapeutic peptides...\n",
      "  âœ“ Aspergillosis Peptide.csv: 1475 valid sequences\n",
      "  âœ“ Breast Cancer Peptide.csv: 347 valid sequences\n",
      "  âœ“ Candidiasis Peptide.csv: 3472 valid sequences\n",
      "  âœ“ Crohnâ€™s Disease.csv: 7 valid sequences\n",
      "  âœ“ Cryptococcosis Peptide.csv: 2918 valid sequences\n",
      "  âœ“ E. coli Infections Peptide.csv: 5167 valid sequences\n",
      "  âœ“ Glioblastoma Peptide.csv: 31 valid sequences\n",
      "  âœ“ Leukemia Peptide.csv: 204 valid sequences\n",
      "  âœ“ Lung Cancer Peptide.csv: 370 valid sequences\n",
      "  âœ“ Melanoma Peptide.csv: 132 valid sequences\n",
      "  âœ“ MRSA Peptide.csv: 877 valid sequences\n",
      "Total non-therapeutic sequences: 15000\n",
      "Overall total: 30000 sequences\n",
      "\n",
      "ðŸ“Š Dataset Statistics by File:\n",
      "  therapeutic_Anti Bacterial Peptide_trimmed.csv: 6,999 sequences\n",
      "  therapeutic_Anti Cancer Peptide_trimmed.csv: 3,999 sequences\n",
      "  therapeutic_Anti Fungal Peptide_trimmed.csv: 4,002 sequences\n",
      "  non_therapeutic_Aspergillosis Peptide.csv: 1,475 sequences\n",
      "  non_therapeutic_Breast Cancer Peptide.csv: 347 sequences\n",
      "  non_therapeutic_Candidiasis Peptide.csv: 3,472 sequences\n",
      "  non_therapeutic_Crohnâ€™s Disease.csv: 7 sequences\n",
      "  non_therapeutic_Cryptococcosis Peptide.csv: 2,918 sequences\n",
      "  non_therapeutic_E. coli Infections Peptide.csv: 5,167 sequences\n",
      "  non_therapeutic_Glioblastoma Peptide.csv: 31 sequences\n",
      "  non_therapeutic_Leukemia Peptide.csv: 204 sequences\n",
      "  non_therapeutic_Lung Cancer Peptide.csv: 370 sequences\n",
      "  non_therapeutic_Melanoma Peptide.csv: 132 sequences\n",
      "  non_therapeutic_MRSA Peptide.csv: 877 sequences\n",
      "\n",
      "Final dataset: 30000 sequences\n",
      "Therapeutic: 15000 (50.0%)\n",
      "Non-therapeutic: 15000 (50.0%)\n",
      "Extracting comprehensive biochemical features...\n",
      "  âœ“ Crohnâ€™s Disease.csv: 7 valid sequences\n",
      "  âœ“ Cryptococcosis Peptide.csv: 2918 valid sequences\n",
      "  âœ“ E. coli Infections Peptide.csv: 5167 valid sequences\n",
      "  âœ“ Glioblastoma Peptide.csv: 31 valid sequences\n",
      "  âœ“ Leukemia Peptide.csv: 204 valid sequences\n",
      "  âœ“ Lung Cancer Peptide.csv: 370 valid sequences\n",
      "  âœ“ Melanoma Peptide.csv: 132 valid sequences\n",
      "  âœ“ MRSA Peptide.csv: 877 valid sequences\n",
      "Total non-therapeutic sequences: 15000\n",
      "Overall total: 30000 sequences\n",
      "\n",
      "ðŸ“Š Dataset Statistics by File:\n",
      "  therapeutic_Anti Bacterial Peptide_trimmed.csv: 6,999 sequences\n",
      "  therapeutic_Anti Cancer Peptide_trimmed.csv: 3,999 sequences\n",
      "  therapeutic_Anti Fungal Peptide_trimmed.csv: 4,002 sequences\n",
      "  non_therapeutic_Aspergillosis Peptide.csv: 1,475 sequences\n",
      "  non_therapeutic_Breast Cancer Peptide.csv: 347 sequences\n",
      "  non_therapeutic_Candidiasis Peptide.csv: 3,472 sequences\n",
      "  non_therapeutic_Crohnâ€™s Disease.csv: 7 sequences\n",
      "  non_therapeutic_Cryptococcosis Peptide.csv: 2,918 sequences\n",
      "  non_therapeutic_E. coli Infections Peptide.csv: 5,167 sequences\n",
      "  non_therapeutic_Glioblastoma Peptide.csv: 31 sequences\n",
      "  non_therapeutic_Leukemia Peptide.csv: 204 sequences\n",
      "  non_therapeutic_Lung Cancer Peptide.csv: 370 sequences\n",
      "  non_therapeutic_Melanoma Peptide.csv: 132 sequences\n",
      "  non_therapeutic_MRSA Peptide.csv: 877 sequences\n",
      "\n",
      "Final dataset: 30000 sequences\n",
      "Therapeutic: 15000 (50.0%)\n",
      "Non-therapeutic: 15000 (50.0%)\n",
      "Extracting comprehensive biochemical features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30000/30000 [00:01<00:00, 21451.99it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction completed: 53 features per sequence\n",
      "Feature matrix shape: (30000, 53)\n",
      "\n",
      "âš–ï¸  Scaling features...\n",
      "ðŸ” Validating data quality...\n",
      "âœ… No NaN values found\n",
      "âœ… No infinite values found\n",
      "ðŸ“Š Label distribution: {0: 15000, 1: 15000}\n",
      "ðŸ“ˆ Feature statistics:\n",
      "  - Feature matrix shape: (30000, 53)\n",
      "  - Min value: -3.835976\n",
      "  - Max value: 54.478451\n",
      "  - Mean: 0.000000\n",
      "  - Std: 1.000000\n",
      "ðŸ§¬ Sequence length statistics:\n",
      "  - Min length: 5\n",
      "  - Max length: 21\n",
      "  - Mean length: 13.9\n",
      "  - Median length: 14.0\n",
      "âœ… Scaler saved to ../backend/models/alternative_models_scaler.pkl\n",
      "\n",
      "ðŸŽ¯ Data preparation completed!\n",
      "  Feature matrix: (30000, 53)\n",
      "  Total sequences: 30000\n",
      "  Data quality validated âœ…\n",
      "  Ready for model training!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ALTERNATIVE MODEL COMPARISON FOR THERAPEUTIC PEPTIDE PREDICTION ===\\n\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(\"../backend/models\", exist_ok=True)\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# Load data with correct relative paths\n",
    "data_path = \"../data\"\n",
    "sequences, labels, file_stats = load_peptide_data(data_path, max_sequences_per_class=15000)\n",
    "\n",
    "# Display dataset statistics\n",
    "if file_stats:\n",
    "    print(\"\\nðŸ“Š Dataset Statistics by File:\")\n",
    "    for file_key, count in file_stats.items():\n",
    "        print(f\"  {file_key}: {count:,} sequences\")\n",
    "\n",
    "print(f\"\\nFinal dataset: {len(sequences)} sequences\")\n",
    "print(f\"Therapeutic: {sum(labels)} ({sum(labels)/len(labels)*100:.1f}%)\")\n",
    "print(f\"Non-therapeutic: {len(labels) - sum(labels)} ({(len(labels) - sum(labels))/len(labels)*100:.1f}%)\")\n",
    "\n",
    "if len(sequences) == 0:\n",
    "    print(\"ERROR: No valid sequences found!\")\n",
    "    print(\"Please check your data files in ../data/Therapeutic data/ and ../data/Non-Therapeutic data/\")\n",
    "    exit()\n",
    "\n",
    "# Extract comprehensive features\n",
    "features = extract_comprehensive_features(sequences)\n",
    "print(f\"Feature matrix shape: {features.shape}\")\n",
    "\n",
    "# Feature scaling\n",
    "print(\"\\nâš–ï¸  Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Basic data quality validation (inline)\n",
    "print(\"ðŸ” Validating data quality...\")\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# Check for NaN values\n",
    "nan_features = np.isnan(features_scaled).sum()\n",
    "if nan_features > 0:\n",
    "    print(f\"âš ï¸  Warning: Found {nan_features} NaN values in features\")\n",
    "    features_scaled = np.nan_to_num(features_scaled)\n",
    "    print(\"âœ… NaN values replaced with zeros\")\n",
    "else:\n",
    "    print(\"âœ… No NaN values found\")\n",
    "\n",
    "# Check for infinite values\n",
    "inf_features = np.isinf(features_scaled).sum()\n",
    "if inf_features > 0:\n",
    "    print(f\"âš ï¸  Warning: Found {inf_features} infinite values in features\")\n",
    "    features_scaled = np.nan_to_num(features_scaled)\n",
    "    print(\"âœ… Infinite values replaced with finite values\")\n",
    "else:\n",
    "    print(\"âœ… No infinite values found\")\n",
    "\n",
    "# Check label distribution\n",
    "unique_labels, counts = np.unique(labels_array, return_counts=True)\n",
    "print(f\"ðŸ“Š Label distribution: {dict(zip(unique_labels, counts))}\")\n",
    "\n",
    "# Feature statistics\n",
    "print(f\"ðŸ“ˆ Feature statistics:\")\n",
    "print(f\"  - Feature matrix shape: {features_scaled.shape}\")\n",
    "print(f\"  - Min value: {features_scaled.min():.6f}\")\n",
    "print(f\"  - Max value: {features_scaled.max():.6f}\")\n",
    "print(f\"  - Mean: {features_scaled.mean():.6f}\")\n",
    "print(f\"  - Std: {features_scaled.std():.6f}\")\n",
    "\n",
    "# Sequence length statistics\n",
    "seq_lengths = [len(seq) for seq in sequences]\n",
    "print(f\"ðŸ§¬ Sequence length statistics:\")\n",
    "print(f\"  - Min length: {min(seq_lengths)}\")\n",
    "print(f\"  - Max length: {max(seq_lengths)}\")\n",
    "print(f\"  - Mean length: {np.mean(seq_lengths):.1f}\")\n",
    "print(f\"  - Median length: {np.median(seq_lengths):.1f}\")\n",
    "\n",
    "# Save scaler\n",
    "with open(\"../backend/models/alternative_models_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"âœ… Scaler saved to ../backend/models/alternative_models_scaler.pkl\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Data preparation completed!\")\n",
    "print(f\"  Feature matrix: {features_scaled.shape}\")\n",
    "print(f\"  Total sequences: {len(sequences)}\")\n",
    "print(f\"  Data quality validated âœ…\")\n",
    "print(f\"  Ready for model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f621c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Utility functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Additional utility functions for robust model training\n",
    "def validate_data_quality(X, y, sequences):\n",
    "    \"\"\"\n",
    "    Validate data quality before training\n",
    "    \"\"\"\n",
    "    print(\"ðŸ” Validating data quality...\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    nan_features = np.isnan(X).sum()\n",
    "    if nan_features > 0:\n",
    "        print(f\"âš ï¸  Warning: Found {nan_features} NaN values in features\")\n",
    "        X = np.nan_to_num(X)\n",
    "        print(\"âœ… NaN values replaced with zeros\")\n",
    "    \n",
    "    # Check for infinite values\n",
    "    inf_features = np.isinf(X).sum()\n",
    "    if inf_features > 0:\n",
    "        print(f\"âš ï¸  Warning: Found {inf_features} infinite values in features\")\n",
    "        X = np.nan_to_num(X)\n",
    "        print(\"âœ… Infinite values replaced with finite values\")\n",
    "    \n",
    "    # Check label distribution\n",
    "    unique_labels, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"ðŸ“Š Label distribution: {dict(zip(unique_labels, counts))}\")\n",
    "    \n",
    "    # Check feature statistics\n",
    "    print(f\"ðŸ“ˆ Feature statistics:\")\n",
    "    print(f\"  - Feature matrix shape: {X.shape}\")\n",
    "    print(f\"  - Min value: {X.min():.6f}\")\n",
    "    print(f\"  - Max value: {X.max():.6f}\")\n",
    "    print(f\"  - Mean: {X.mean():.6f}\")\n",
    "    print(f\"  - Std: {X.std():.6f}\")\n",
    "    \n",
    "    # Check sequence lengths\n",
    "    seq_lengths = [len(seq) for seq in sequences]\n",
    "    print(f\"ðŸ§¬ Sequence length statistics:\")\n",
    "    print(f\"  - Min length: {min(seq_lengths)}\")\n",
    "    print(f\"  - Max length: {max(seq_lengths)}\")\n",
    "    print(f\"  - Mean length: {np.mean(seq_lengths):.1f}\")\n",
    "    print(f\"  - Median length: {np.median(seq_lengths):.1f}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_model_checkpoint_callback(model_name, monitor='val_loss', patience=15):\n",
    "    \"\"\"\n",
    "    Create standardized callbacks for model training\n",
    "    \"\"\"\n",
    "    return [\n",
    "        EarlyStopping(\n",
    "            monitor=monitor, \n",
    "            patience=patience, \n",
    "            restore_best_weights=True, \n",
    "            verbose=1,\n",
    "            mode='min' if 'loss' in monitor else 'max'\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            f'../backend/models/{model_name}.h5', \n",
    "            save_best_only=True, \n",
    "            monitor=monitor, \n",
    "            verbose=1,\n",
    "            mode='min' if 'loss' in monitor else 'max'\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor=monitor, \n",
    "            factor=0.5, \n",
    "            patience=max(5, patience//3), \n",
    "            min_lr=1e-7, \n",
    "            verbose=1,\n",
    "            mode='min' if 'loss' in monitor else 'max'\n",
    "        )\n",
    "    ]\n",
    "\n",
    "def print_training_summary(model_name, history, results):\n",
    "    \"\"\"\n",
    "    Print comprehensive training summary\n",
    "    \"\"\"\n",
    "    if history is not None and results is not None:\n",
    "        acc, prec, rec = results[1], results[2], results[3]\n",
    "        f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "        \n",
    "        print(f\"\\nðŸ“Š {model_name} Training Summary:\")\n",
    "        print(f\"  â€¢ Epochs trained: {len(history.history['loss'])}\")\n",
    "        print(f\"  â€¢ Final training loss: {history.history['loss'][-1]:.4f}\")\n",
    "        print(f\"  â€¢ Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "        print(f\"  â€¢ Best validation accuracy: {max(history.history.get('val_accuracy', [0])):.4f}\")\n",
    "        print(f\"  â€¢ Test accuracy: {acc:.4f}\")\n",
    "        print(f\"  â€¢ Test precision: {prec:.4f}\")\n",
    "        print(f\"  â€¢ Test recall: {rec:.4f}\")\n",
    "        print(f\"  â€¢ Test F1-score: {f1:.4f}\")\n",
    "        \n",
    "        return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}\n",
    "    return None\n",
    "\n",
    "print(\"âœ… Utility functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9989494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Data Split:\n",
      "  Training: 24000 samples\n",
      "  Testing: 6000 samples\n",
      "  Features: 53\n",
      "  Labels converted to numpy arrays: y_train.shape = (24000,), y_test.shape = (6000,)\n",
      "\n",
      "ðŸ—ï¸  Training Advanced Dense Neural Network...\n",
      "Dense model created with 59,393 parameters\n",
      "Epoch 1/100\n",
      "Dense model created with 59,393 parameters\n",
      "Epoch 1/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.4186 - accuracy: 0.8057 - precision: 0.8106 - recall: 0.7974\n",
      "Epoch 1: val_loss improved from inf to 0.22790, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.22790, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 4s 7ms/step - loss: 0.4178 - accuracy: 0.8063 - precision: 0.8117 - recall: 0.7977 - val_loss: 0.2279 - val_accuracy: 0.9095 - val_precision: 0.9525 - val_recall: 0.8620 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 4s 7ms/step - loss: 0.4178 - accuracy: 0.8063 - precision: 0.8117 - recall: 0.7977 - val_loss: 0.2279 - val_accuracy: 0.9095 - val_precision: 0.9525 - val_recall: 0.8620 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.2741 - accuracy: 0.8947 - precision: 0.9176 - recall: 0.8676\n",
      "Epoch 2: val_loss improved from 0.22790 to 0.18114, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.22790 to 0.18114, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2742 - accuracy: 0.8948 - precision: 0.9174 - recall: 0.8677 - val_loss: 0.1811 - val_accuracy: 0.9297 - val_precision: 0.9647 - val_recall: 0.8920 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2742 - accuracy: 0.8948 - precision: 0.9174 - recall: 0.8677 - val_loss: 0.1811 - val_accuracy: 0.9297 - val_precision: 0.9647 - val_recall: 0.8920 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.9097 - precision: 0.9360 - recall: 0.8795\n",
      "Epoch 3: val_loss improved from 0.18114 to 0.17097, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.18114 to 0.17097, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2298 - accuracy: 0.9094 - precision: 0.9358 - recall: 0.8792 - val_loss: 0.1710 - val_accuracy: 0.9385 - val_precision: 0.9582 - val_recall: 0.9170 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2298 - accuracy: 0.9094 - precision: 0.9358 - recall: 0.8792 - val_loss: 0.1710 - val_accuracy: 0.9385 - val_precision: 0.9582 - val_recall: 0.9170 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.2083 - accuracy: 0.9194 - precision: 0.9451 - recall: 0.8907\n",
      "Epoch 4: val_loss improved from 0.17097 to 0.15329, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.17097 to 0.15329, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.2083 - accuracy: 0.9195 - precision: 0.9452 - recall: 0.8907 - val_loss: 0.1533 - val_accuracy: 0.9423 - val_precision: 0.9689 - val_recall: 0.9140 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.2083 - accuracy: 0.9195 - precision: 0.9452 - recall: 0.8907 - val_loss: 0.1533 - val_accuracy: 0.9423 - val_precision: 0.9689 - val_recall: 0.9140 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9285 - precision: 0.9546 - recall: 0.9000\n",
      "Epoch 5: val_loss improved from 0.15329 to 0.13789, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.15329 to 0.13789, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1899 - accuracy: 0.9288 - precision: 0.9549 - recall: 0.9002 - val_loss: 0.1379 - val_accuracy: 0.9465 - val_precision: 0.9779 - val_recall: 0.9137 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1899 - accuracy: 0.9288 - precision: 0.9549 - recall: 0.9002 - val_loss: 0.1379 - val_accuracy: 0.9465 - val_precision: 0.9779 - val_recall: 0.9137 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.1797 - accuracy: 0.9320 - precision: 0.9562 - recall: 0.9055\n",
      "Epoch 6: val_loss improved from 0.13789 to 0.13129, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.13789 to 0.13129, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1793 - accuracy: 0.9324 - precision: 0.9563 - recall: 0.9062 - val_loss: 0.1313 - val_accuracy: 0.9515 - val_precision: 0.9741 - val_recall: 0.9277 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1793 - accuracy: 0.9324 - precision: 0.9563 - recall: 0.9062 - val_loss: 0.1313 - val_accuracy: 0.9515 - val_precision: 0.9741 - val_recall: 0.9277 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.1685 - accuracy: 0.9376 - precision: 0.9607 - recall: 0.9125\n",
      "Epoch 7: val_loss improved from 0.13129 to 0.12003, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.13129 to 0.12003, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1679 - accuracy: 0.9379 - precision: 0.9610 - recall: 0.9128 - val_loss: 0.1200 - val_accuracy: 0.9573 - val_precision: 0.9794 - val_recall: 0.9343 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1679 - accuracy: 0.9379 - precision: 0.9610 - recall: 0.9128 - val_loss: 0.1200 - val_accuracy: 0.9573 - val_precision: 0.9794 - val_recall: 0.9343 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "366/375 [============================>.] - ETA: 0s - loss: 0.1543 - accuracy: 0.9445 - precision: 0.9681 - recall: 0.9193\n",
      "Epoch 8: val_loss improved from 0.12003 to 0.11948, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.12003 to 0.11948, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1543 - accuracy: 0.9445 - precision: 0.9682 - recall: 0.9193 - val_loss: 0.1195 - val_accuracy: 0.9587 - val_precision: 0.9828 - val_recall: 0.9337 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1543 - accuracy: 0.9445 - precision: 0.9682 - recall: 0.9193 - val_loss: 0.1195 - val_accuracy: 0.9587 - val_precision: 0.9828 - val_recall: 0.9337 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9440 - precision: 0.9649 - recall: 0.9217\n",
      "Epoch 9: val_loss improved from 0.11948 to 0.11182, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.11948 to 0.11182, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1553 - accuracy: 0.9441 - precision: 0.9645 - recall: 0.9222 - val_loss: 0.1118 - val_accuracy: 0.9620 - val_precision: 0.9783 - val_recall: 0.9450 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1553 - accuracy: 0.9441 - precision: 0.9645 - recall: 0.9222 - val_loss: 0.1118 - val_accuracy: 0.9620 - val_precision: 0.9783 - val_recall: 0.9450 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1430 - accuracy: 0.9475 - precision: 0.9689 - recall: 0.9247\n",
      "Epoch 10: val_loss improved from 0.11182 to 0.11140, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.11182 to 0.11140, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1430 - accuracy: 0.9475 - precision: 0.9688 - recall: 0.9248 - val_loss: 0.1114 - val_accuracy: 0.9607 - val_precision: 0.9842 - val_recall: 0.9363 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1430 - accuracy: 0.9475 - precision: 0.9688 - recall: 0.9248 - val_loss: 0.1114 - val_accuracy: 0.9607 - val_precision: 0.9842 - val_recall: 0.9363 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.1400 - accuracy: 0.9494 - precision: 0.9691 - recall: 0.9284\n",
      "Epoch 11: val_loss improved from 0.11140 to 0.10344, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.11140 to 0.10344, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1402 - accuracy: 0.9492 - precision: 0.9690 - recall: 0.9281 - val_loss: 0.1034 - val_accuracy: 0.9647 - val_precision: 0.9895 - val_recall: 0.9393 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1402 - accuracy: 0.9492 - precision: 0.9690 - recall: 0.9281 - val_loss: 0.1034 - val_accuracy: 0.9647 - val_precision: 0.9895 - val_recall: 0.9393 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.1334 - accuracy: 0.9531 - precision: 0.9717 - recall: 0.9333\n",
      "Epoch 12: val_loss improved from 0.10344 to 0.10255, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.10344 to 0.10255, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1339 - accuracy: 0.9529 - precision: 0.9715 - recall: 0.9332 - val_loss: 0.1026 - val_accuracy: 0.9632 - val_precision: 0.9810 - val_recall: 0.9447 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1339 - accuracy: 0.9529 - precision: 0.9715 - recall: 0.9332 - val_loss: 0.1026 - val_accuracy: 0.9632 - val_precision: 0.9810 - val_recall: 0.9447 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9541 - precision: 0.9709 - recall: 0.9360\n",
      "Epoch 13: val_loss improved from 0.10255 to 0.09956, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.10255 to 0.09956, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1270 - accuracy: 0.9540 - precision: 0.9714 - recall: 0.9356 - val_loss: 0.0996 - val_accuracy: 0.9663 - val_precision: 0.9794 - val_recall: 0.9527 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1270 - accuracy: 0.9540 - precision: 0.9714 - recall: 0.9356 - val_loss: 0.0996 - val_accuracy: 0.9663 - val_precision: 0.9794 - val_recall: 0.9527 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.1240 - accuracy: 0.9550 - precision: 0.9734 - recall: 0.9356\n",
      "Epoch 14: val_loss did not improve from 0.09956\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1239 - accuracy: 0.9548 - precision: 0.9734 - recall: 0.9352 - val_loss: 0.1021 - val_accuracy: 0.9640 - val_precision: 0.9784 - val_recall: 0.9490 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0361 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 14: val_loss did not improve from 0.09956\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1239 - accuracy: 0.9548 - precision: 0.9734 - recall: 0.9352 - val_loss: 0.1021 - val_accuracy: 0.9640 - val_precision: 0.9784 - val_recall: 0.9490 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "365/375 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.9594 - precision: 0.9758 - recall: 0.9421\n",
      "Epoch 15: val_loss did not improve from 0.09956\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1211 - accuracy: 0.9595 - precision: 0.9760 - recall: 0.9421 - val_loss: 0.1040 - val_accuracy: 0.9640 - val_precision: 0.9784 - val_recall: 0.9490 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0831 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9697\n",
      "Epoch 15: val_loss did not improve from 0.09956\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1211 - accuracy: 0.9595 - precision: 0.9760 - recall: 0.9421 - val_loss: 0.1040 - val_accuracy: 0.9640 - val_precision: 0.9784 - val_recall: 0.9490 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.9577 - precision: 0.9757 - recall: 0.9387\n",
      "Epoch 16: val_loss improved from 0.09956 to 0.09776, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.09956 to 0.09776, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1173 - accuracy: 0.9577 - precision: 0.9756 - recall: 0.9389 - val_loss: 0.0978 - val_accuracy: 0.9665 - val_precision: 0.9844 - val_recall: 0.9480 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1173 - accuracy: 0.9577 - precision: 0.9756 - recall: 0.9389 - val_loss: 0.0978 - val_accuracy: 0.9665 - val_precision: 0.9844 - val_recall: 0.9480 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.9593 - precision: 0.9770 - recall: 0.9408\n",
      "Epoch 17: val_loss improved from 0.09776 to 0.09426, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.09776 to 0.09426, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1158 - accuracy: 0.9592 - precision: 0.9770 - recall: 0.9407 - val_loss: 0.0943 - val_accuracy: 0.9673 - val_precision: 0.9788 - val_recall: 0.9553 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1158 - accuracy: 0.9592 - precision: 0.9770 - recall: 0.9407 - val_loss: 0.0943 - val_accuracy: 0.9673 - val_precision: 0.9788 - val_recall: 0.9553 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9585 - precision: 0.9757 - recall: 0.9404\n",
      "Epoch 18: val_loss did not improve from 0.09426\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1167 - accuracy: 0.9585 - precision: 0.9758 - recall: 0.9403 - val_loss: 0.0982 - val_accuracy: 0.9668 - val_precision: 0.9878 - val_recall: 0.9453 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0563 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9697\n",
      "Epoch 18: val_loss did not improve from 0.09426\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1167 - accuracy: 0.9585 - precision: 0.9758 - recall: 0.9403 - val_loss: 0.0982 - val_accuracy: 0.9668 - val_precision: 0.9878 - val_recall: 0.9453 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9587 - precision: 0.9761 - recall: 0.9404\n",
      "Epoch 19: val_loss did not improve from 0.09426\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1153 - accuracy: 0.9585 - precision: 0.9761 - recall: 0.9401 - val_loss: 0.0958 - val_accuracy: 0.9685 - val_precision: 0.9832 - val_recall: 0.9533 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "  1/375 [..............................] - ETA: 3s - loss: 0.1086 - accuracy: 0.9844 - precision: 0.9583 - recall: 1.0000\n",
      "Epoch 19: val_loss did not improve from 0.09426\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1153 - accuracy: 0.9585 - precision: 0.9761 - recall: 0.9401 - val_loss: 0.0958 - val_accuracy: 0.9685 - val_precision: 0.9832 - val_recall: 0.9533 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "366/375 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9607 - precision: 0.9783 - recall: 0.9423\n",
      "Epoch 20: val_loss did not improve from 0.09426\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1098 - accuracy: 0.9606 - precision: 0.9782 - recall: 0.9422 - val_loss: 0.0982 - val_accuracy: 0.9663 - val_precision: 0.9801 - val_recall: 0.9520 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0913 - accuracy: 0.9688 - precision: 0.9630 - recall: 0.9630\n",
      "Epoch 20: val_loss did not improve from 0.09426\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1098 - accuracy: 0.9606 - precision: 0.9782 - recall: 0.9422 - val_loss: 0.0982 - val_accuracy: 0.9663 - val_precision: 0.9801 - val_recall: 0.9520 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9617 - precision: 0.9782 - recall: 0.9444\n",
      "Epoch 21: val_loss improved from 0.09426 to 0.09081, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.09426 to 0.09081, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1106 - accuracy: 0.9617 - precision: 0.9782 - recall: 0.9444 - val_loss: 0.0908 - val_accuracy: 0.9702 - val_precision: 0.9876 - val_recall: 0.9523 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1106 - accuracy: 0.9617 - precision: 0.9782 - recall: 0.9444 - val_loss: 0.0908 - val_accuracy: 0.9702 - val_precision: 0.9876 - val_recall: 0.9523 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.9639 - precision: 0.9794 - recall: 0.9479\n",
      "Epoch 22: val_loss did not improve from 0.09081\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1052 - accuracy: 0.9638 - precision: 0.9792 - recall: 0.9478 - val_loss: 0.0912 - val_accuracy: 0.9697 - val_precision: 0.9780 - val_recall: 0.9610 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "  1/375 [..............................] - ETA: 1s - loss: 0.0446 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 22: val_loss did not improve from 0.09081\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1052 - accuracy: 0.9638 - precision: 0.9792 - recall: 0.9478 - val_loss: 0.0912 - val_accuracy: 0.9697 - val_precision: 0.9780 - val_recall: 0.9610 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9633 - precision: 0.9800 - recall: 0.9460\n",
      "Epoch 23: val_loss did not improve from 0.09081\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1022 - accuracy: 0.9636 - precision: 0.9800 - recall: 0.9466 - val_loss: 0.0929 - val_accuracy: 0.9703 - val_precision: 0.9872 - val_recall: 0.9530 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0711 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9706\n",
      "Epoch 23: val_loss did not improve from 0.09081\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1022 - accuracy: 0.9636 - precision: 0.9800 - recall: 0.9466 - val_loss: 0.0929 - val_accuracy: 0.9703 - val_precision: 0.9872 - val_recall: 0.9530 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.9646 - precision: 0.9816 - recall: 0.9470\n",
      "Epoch 24: val_loss improved from 0.09081 to 0.09067, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.09081 to 0.09067, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1006 - accuracy: 0.9645 - precision: 0.9817 - recall: 0.9467 - val_loss: 0.0907 - val_accuracy: 0.9703 - val_precision: 0.9819 - val_recall: 0.9583 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1006 - accuracy: 0.9645 - precision: 0.9817 - recall: 0.9467 - val_loss: 0.0907 - val_accuracy: 0.9703 - val_precision: 0.9819 - val_recall: 0.9583 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.9644 - precision: 0.9785 - recall: 0.9495\n",
      "Epoch 25: val_loss did not improve from 0.09067\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0995 - accuracy: 0.9646 - precision: 0.9787 - recall: 0.9498 - val_loss: 0.0946 - val_accuracy: 0.9692 - val_precision: 0.9802 - val_recall: 0.9577 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.1275 - accuracy: 0.9375 - precision: 0.9697 - recall: 0.9143\n",
      "Epoch 25: val_loss did not improve from 0.09067\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0995 - accuracy: 0.9646 - precision: 0.9787 - recall: 0.9498 - val_loss: 0.0946 - val_accuracy: 0.9692 - val_precision: 0.9802 - val_recall: 0.9577 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9659 - precision: 0.9810 - recall: 0.9502\n",
      "Epoch 26: val_loss did not improve from 0.09067\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1004 - accuracy: 0.9660 - precision: 0.9811 - recall: 0.9503 - val_loss: 0.0917 - val_accuracy: 0.9688 - val_precision: 0.9838 - val_recall: 0.9533 - lr: 0.0010\n",
      "Epoch 27/100\n",
      " 19/375 [>.............................] - ETA: 2s - loss: 0.0891 - accuracy: 0.9679 - precision: 0.9802 - recall: 0.9566\n",
      "Epoch 26: val_loss did not improve from 0.09067\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1004 - accuracy: 0.9660 - precision: 0.9811 - recall: 0.9503 - val_loss: 0.0917 - val_accuracy: 0.9688 - val_precision: 0.9838 - val_recall: 0.9533 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9658 - precision: 0.9814 - recall: 0.9495\n",
      "Epoch 27: val_loss did not improve from 0.09067\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0970 - accuracy: 0.9655 - precision: 0.9813 - recall: 0.9492 - val_loss: 0.0913 - val_accuracy: 0.9688 - val_precision: 0.9763 - val_recall: 0.9610 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0580 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9655\n",
      "Epoch 27: val_loss did not improve from 0.09067\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0970 - accuracy: 0.9655 - precision: 0.9813 - recall: 0.9492 - val_loss: 0.0913 - val_accuracy: 0.9688 - val_precision: 0.9763 - val_recall: 0.9610 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9655 - precision: 0.9813 - recall: 0.9491\n",
      "Epoch 28: val_loss improved from 0.09067 to 0.08524, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.09067 to 0.08524, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0974 - accuracy: 0.9657 - precision: 0.9816 - recall: 0.9492 - val_loss: 0.0852 - val_accuracy: 0.9725 - val_precision: 0.9876 - val_recall: 0.9570 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0974 - accuracy: 0.9657 - precision: 0.9816 - recall: 0.9492 - val_loss: 0.0852 - val_accuracy: 0.9725 - val_precision: 0.9876 - val_recall: 0.9570 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9673 - precision: 0.9833 - recall: 0.9507\n",
      "Epoch 29: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0940 - accuracy: 0.9674 - precision: 0.9834 - recall: 0.9507 - val_loss: 0.0888 - val_accuracy: 0.9723 - val_precision: 0.9836 - val_recall: 0.9607 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0475 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9677\n",
      "Epoch 29: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0940 - accuracy: 0.9674 - precision: 0.9834 - recall: 0.9507 - val_loss: 0.0888 - val_accuracy: 0.9723 - val_precision: 0.9836 - val_recall: 0.9607 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9685 - precision: 0.9831 - recall: 0.9532\n",
      "Epoch 30: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0916 - accuracy: 0.9686 - precision: 0.9833 - recall: 0.9534 - val_loss: 0.0862 - val_accuracy: 0.9713 - val_precision: 0.9796 - val_recall: 0.9627 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "  1/375 [..............................] - ETA: 1s - loss: 0.1689 - accuracy: 0.9531 - precision: 1.0000 - recall: 0.9211\n",
      "Epoch 30: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0916 - accuracy: 0.9686 - precision: 0.9833 - recall: 0.9534 - val_loss: 0.0862 - val_accuracy: 0.9713 - val_precision: 0.9796 - val_recall: 0.9627 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9671 - precision: 0.9812 - recall: 0.9524\n",
      "Epoch 31: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0926 - accuracy: 0.9669 - precision: 0.9811 - recall: 0.9521 - val_loss: 0.0866 - val_accuracy: 0.9725 - val_precision: 0.9833 - val_recall: 0.9613 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0926 - accuracy: 0.9669 - precision: 0.9811 - recall: 0.9521 - val_loss: 0.0866 - val_accuracy: 0.9725 - val_precision: 0.9833 - val_recall: 0.9613 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "366/375 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9697 - precision: 0.9835 - recall: 0.9554\n",
      "Epoch 32: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0884 - accuracy: 0.9700 - precision: 0.9838 - recall: 0.9557 - val_loss: 0.0907 - val_accuracy: 0.9710 - val_precision: 0.9823 - val_recall: 0.9593 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "  1/375 [..............................] - ETA: 1s - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0884 - accuracy: 0.9700 - precision: 0.9838 - recall: 0.9557 - val_loss: 0.0907 - val_accuracy: 0.9710 - val_precision: 0.9823 - val_recall: 0.9593 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0907 - accuracy: 0.9686 - precision: 0.9839 - recall: 0.9528\n",
      "Epoch 33: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0906 - accuracy: 0.9687 - precision: 0.9839 - recall: 0.9529 - val_loss: 0.0855 - val_accuracy: 0.9700 - val_precision: 0.9789 - val_recall: 0.9607 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0437 - accuracy: 0.9844 - precision: 0.9706 - recall: 1.0000\n",
      "Epoch 33: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0906 - accuracy: 0.9687 - precision: 0.9839 - recall: 0.9529 - val_loss: 0.0855 - val_accuracy: 0.9700 - val_precision: 0.9789 - val_recall: 0.9607 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0882 - accuracy: 0.9698 - precision: 0.9840 - recall: 0.9551\n",
      "Epoch 34: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0887 - accuracy: 0.9695 - precision: 0.9839 - recall: 0.9548 - val_loss: 0.0855 - val_accuracy: 0.9712 - val_precision: 0.9872 - val_recall: 0.9547 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0887 - accuracy: 0.9695 - precision: 0.9839 - recall: 0.9548 - val_loss: 0.0855 - val_accuracy: 0.9712 - val_precision: 0.9872 - val_recall: 0.9547 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9690 - precision: 0.9838 - recall: 0.9536\n",
      "Epoch 35: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0904 - accuracy: 0.9690 - precision: 0.9838 - recall: 0.9538 - val_loss: 0.0888 - val_accuracy: 0.9722 - val_precision: 0.9843 - val_recall: 0.9597 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0289 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9688\n",
      "Epoch 35: val_loss did not improve from 0.08524\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0904 - accuracy: 0.9690 - precision: 0.9838 - recall: 0.9538 - val_loss: 0.0888 - val_accuracy: 0.9722 - val_precision: 0.9843 - val_recall: 0.9597 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.9701 - precision: 0.9832 - recall: 0.9564\n",
      "Epoch 36: val_loss did not improve from 0.08524\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0849 - accuracy: 0.9700 - precision: 0.9832 - recall: 0.9563 - val_loss: 0.0870 - val_accuracy: 0.9703 - val_precision: 0.9849 - val_recall: 0.9553 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.1325 - accuracy: 0.9375 - precision: 0.8750 - recall: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.08524\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0849 - accuracy: 0.9700 - precision: 0.9832 - recall: 0.9563 - val_loss: 0.0870 - val_accuracy: 0.9703 - val_precision: 0.9849 - val_recall: 0.9553 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9709 - precision: 0.9829 - recall: 0.9585\n",
      "Epoch 37: val_loss improved from 0.08524 to 0.08292, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.08524 to 0.08292, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0800 - accuracy: 0.9709 - precision: 0.9828 - recall: 0.9586 - val_loss: 0.0829 - val_accuracy: 0.9737 - val_precision: 0.9863 - val_recall: 0.9607 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0800 - accuracy: 0.9709 - precision: 0.9828 - recall: 0.9586 - val_loss: 0.0829 - val_accuracy: 0.9737 - val_precision: 0.9863 - val_recall: 0.9607 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0799 - accuracy: 0.9722 - precision: 0.9845 - recall: 0.9594\n",
      "Epoch 38: val_loss improved from 0.08292 to 0.08261, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 38: val_loss improved from 0.08292 to 0.08261, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0797 - accuracy: 0.9722 - precision: 0.9845 - recall: 0.9595 - val_loss: 0.0826 - val_accuracy: 0.9740 - val_precision: 0.9824 - val_recall: 0.9653 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0797 - accuracy: 0.9722 - precision: 0.9845 - recall: 0.9595 - val_loss: 0.0826 - val_accuracy: 0.9740 - val_precision: 0.9824 - val_recall: 0.9653 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9723 - precision: 0.9840 - recall: 0.9601\n",
      "Epoch 39: val_loss did not improve from 0.08261\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0766 - accuracy: 0.9725 - precision: 0.9841 - recall: 0.9604 - val_loss: 0.0834 - val_accuracy: 0.9740 - val_precision: 0.9857 - val_recall: 0.9620 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0647 - accuracy: 0.9844 - precision: 0.9655 - recall: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.08261\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0766 - accuracy: 0.9725 - precision: 0.9841 - recall: 0.9604 - val_loss: 0.0834 - val_accuracy: 0.9740 - val_precision: 0.9857 - val_recall: 0.9620 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9735 - precision: 0.9861 - recall: 0.9605\n",
      "Epoch 40: val_loss improved from 0.08261 to 0.08153, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.08261 to 0.08153, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0747 - accuracy: 0.9736 - precision: 0.9861 - recall: 0.9607 - val_loss: 0.0815 - val_accuracy: 0.9745 - val_precision: 0.9857 - val_recall: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0747 - accuracy: 0.9736 - precision: 0.9861 - recall: 0.9607 - val_loss: 0.0815 - val_accuracy: 0.9745 - val_precision: 0.9857 - val_recall: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 41/100\n",
      "366/375 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9736 - precision: 0.9861 - recall: 0.9606\n",
      "Epoch 41: val_loss improved from 0.08153 to 0.08149, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 41: val_loss improved from 0.08153 to 0.08149, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0747 - accuracy: 0.9737 - precision: 0.9862 - recall: 0.9607 - val_loss: 0.0815 - val_accuracy: 0.9738 - val_precision: 0.9857 - val_recall: 0.9617 - lr: 5.0000e-04\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0747 - accuracy: 0.9737 - precision: 0.9862 - recall: 0.9607 - val_loss: 0.0815 - val_accuracy: 0.9738 - val_precision: 0.9857 - val_recall: 0.9617 - lr: 5.0000e-04\n",
      "Epoch 42/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9740 - precision: 0.9860 - recall: 0.9616\n",
      "Epoch 42: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0742 - accuracy: 0.9739 - precision: 0.9858 - recall: 0.9617 - val_loss: 0.0845 - val_accuracy: 0.9727 - val_precision: 0.9791 - val_recall: 0.9660 - lr: 5.0000e-04\n",
      "Epoch 43/100\n",
      "  1/375 [..............................] - ETA: 1s - loss: 0.0839 - accuracy: 0.9688 - precision: 0.9600 - recall: 0.9600\n",
      "Epoch 42: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0742 - accuracy: 0.9739 - precision: 0.9858 - recall: 0.9617 - val_loss: 0.0845 - val_accuracy: 0.9727 - val_precision: 0.9791 - val_recall: 0.9660 - lr: 5.0000e-04\n",
      "Epoch 43/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 0.9754 - precision: 0.9863 - recall: 0.9643\n",
      "Epoch 43: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0721 - accuracy: 0.9756 - precision: 0.9864 - recall: 0.9645 - val_loss: 0.0842 - val_accuracy: 0.9728 - val_precision: 0.9823 - val_recall: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 44/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0995 - accuracy: 0.9531 - precision: 1.0000 - recall: 0.9000\n",
      "Epoch 43: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0721 - accuracy: 0.9756 - precision: 0.9864 - recall: 0.9645 - val_loss: 0.0842 - val_accuracy: 0.9728 - val_precision: 0.9823 - val_recall: 0.9630 - lr: 5.0000e-04\n",
      "Epoch 44/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9760 - precision: 0.9885 - recall: 0.9632\n",
      "Epoch 44: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0701 - accuracy: 0.9759 - precision: 0.9883 - recall: 0.9632 - val_loss: 0.0850 - val_accuracy: 0.9732 - val_precision: 0.9823 - val_recall: 0.9637 - lr: 5.0000e-04\n",
      "Epoch 45/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0162 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0701 - accuracy: 0.9759 - precision: 0.9883 - recall: 0.9632 - val_loss: 0.0850 - val_accuracy: 0.9732 - val_precision: 0.9823 - val_recall: 0.9637 - lr: 5.0000e-04\n",
      "Epoch 45/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9754 - precision: 0.9874 - recall: 0.9631\n",
      "Epoch 45: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0717 - accuracy: 0.9753 - precision: 0.9873 - recall: 0.9630 - val_loss: 0.0829 - val_accuracy: 0.9742 - val_precision: 0.9837 - val_recall: 0.9643 - lr: 5.0000e-04\n",
      "Epoch 46/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0858 - accuracy: 0.9375 - precision: 0.8846 - recall: 0.9583\n",
      "Epoch 45: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0717 - accuracy: 0.9753 - precision: 0.9873 - recall: 0.9630 - val_loss: 0.0829 - val_accuracy: 0.9742 - val_precision: 0.9837 - val_recall: 0.9643 - lr: 5.0000e-04\n",
      "Epoch 46/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9761 - precision: 0.9870 - recall: 0.9648\n",
      "Epoch 46: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0703 - accuracy: 0.9759 - precision: 0.9868 - recall: 0.9647 - val_loss: 0.0828 - val_accuracy: 0.9755 - val_precision: 0.9844 - val_recall: 0.9663 - lr: 5.0000e-04\n",
      "Epoch 47/100\n",
      "  1/375 [..............................] - ETA: 1s - loss: 0.0477 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9706\n",
      "Epoch 46: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0703 - accuracy: 0.9759 - precision: 0.9868 - recall: 0.9647 - val_loss: 0.0828 - val_accuracy: 0.9755 - val_precision: 0.9844 - val_recall: 0.9663 - lr: 5.0000e-04\n",
      "Epoch 47/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9741 - precision: 0.9850 - recall: 0.9628\n",
      "Epoch 47: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0715 - accuracy: 0.9740 - precision: 0.9851 - recall: 0.9627 - val_loss: 0.0824 - val_accuracy: 0.9735 - val_precision: 0.9830 - val_recall: 0.9637 - lr: 5.0000e-04\n",
      "Epoch 48/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.1214 - accuracy: 0.9531 - precision: 1.0000 - recall: 0.9211\n",
      "Epoch 47: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0715 - accuracy: 0.9740 - precision: 0.9851 - recall: 0.9627 - val_loss: 0.0824 - val_accuracy: 0.9735 - val_precision: 0.9830 - val_recall: 0.9637 - lr: 5.0000e-04\n",
      "Epoch 48/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0687 - accuracy: 0.9761 - precision: 0.9875 - recall: 0.9644\n",
      "Epoch 48: val_loss did not improve from 0.08149\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0686 - accuracy: 0.9762 - precision: 0.9876 - recall: 0.9644 - val_loss: 0.0835 - val_accuracy: 0.9740 - val_precision: 0.9840 - val_recall: 0.9637 - lr: 5.0000e-04\n",
      "Epoch 49/100\n",
      "  1/375 [..............................] - ETA: 1s - loss: 0.0215 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.08149\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0686 - accuracy: 0.9762 - precision: 0.9876 - recall: 0.9644 - val_loss: 0.0835 - val_accuracy: 0.9740 - val_precision: 0.9840 - val_recall: 0.9637 - lr: 5.0000e-04\n",
      "Epoch 49/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9766 - precision: 0.9883 - recall: 0.9646\n",
      "Epoch 49: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0672 - accuracy: 0.9767 - precision: 0.9884 - recall: 0.9647 - val_loss: 0.0823 - val_accuracy: 0.9747 - val_precision: 0.9847 - val_recall: 0.9643 - lr: 2.5000e-04\n",
      "Epoch 50/100\n",
      "  1/375 [..............................] - ETA: 1s - loss: 0.1179 - accuracy: 0.9531 - precision: 0.9697 - recall: 0.9412\n",
      "Epoch 49: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0672 - accuracy: 0.9767 - precision: 0.9884 - recall: 0.9647 - val_loss: 0.0823 - val_accuracy: 0.9747 - val_precision: 0.9847 - val_recall: 0.9643 - lr: 2.5000e-04\n",
      "Epoch 50/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9762 - precision: 0.9878 - recall: 0.9643\n",
      "Epoch 50: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0683 - accuracy: 0.9761 - precision: 0.9880 - recall: 0.9639 - val_loss: 0.0820 - val_accuracy: 0.9753 - val_precision: 0.9854 - val_recall: 0.9650 - lr: 2.5000e-04\n",
      "Epoch 51/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0273 - accuracy: 0.9844 - precision: 0.9667 - recall: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0683 - accuracy: 0.9761 - precision: 0.9880 - recall: 0.9639 - val_loss: 0.0820 - val_accuracy: 0.9753 - val_precision: 0.9854 - val_recall: 0.9650 - lr: 2.5000e-04\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9768 - precision: 0.9884 - recall: 0.9648\n",
      "Epoch 51: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0661 - accuracy: 0.9768 - precision: 0.9884 - recall: 0.9648 - val_loss: 0.0824 - val_accuracy: 0.9742 - val_precision: 0.9827 - val_recall: 0.9653 - lr: 2.5000e-04\n",
      "Epoch 52/100\n",
      "  1/375 [..............................] - ETA: 1s - loss: 0.1007 - accuracy: 0.9531 - precision: 0.9310 - recall: 0.9643\n",
      "Epoch 51: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0661 - accuracy: 0.9768 - precision: 0.9884 - recall: 0.9648 - val_loss: 0.0824 - val_accuracy: 0.9742 - val_precision: 0.9827 - val_recall: 0.9653 - lr: 2.5000e-04\n",
      "Epoch 52/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9771 - precision: 0.9870 - recall: 0.9670\n",
      "Epoch 52: val_loss improved from 0.08149 to 0.08149, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "\n",
      "Epoch 52: val_loss improved from 0.08149 to 0.08149, saving model to ../backend/models\\advanced_dense_model.h5\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0658 - accuracy: 0.9772 - precision: 0.9871 - recall: 0.9672 - val_loss: 0.0815 - val_accuracy: 0.9740 - val_precision: 0.9824 - val_recall: 0.9653 - lr: 2.5000e-04\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0658 - accuracy: 0.9772 - precision: 0.9871 - recall: 0.9672 - val_loss: 0.0815 - val_accuracy: 0.9740 - val_precision: 0.9824 - val_recall: 0.9653 - lr: 2.5000e-04\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9782 - precision: 0.9903 - recall: 0.9657\n",
      "Epoch 53: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0655 - accuracy: 0.9782 - precision: 0.9903 - recall: 0.9657 - val_loss: 0.0823 - val_accuracy: 0.9745 - val_precision: 0.9824 - val_recall: 0.9663 - lr: 2.5000e-04\n",
      "Epoch 54/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0818 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9722\n",
      "Epoch 53: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0655 - accuracy: 0.9782 - precision: 0.9903 - recall: 0.9657 - val_loss: 0.0823 - val_accuracy: 0.9745 - val_precision: 0.9824 - val_recall: 0.9663 - lr: 2.5000e-04\n",
      "Epoch 54/100\n",
      "366/375 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9786 - precision: 0.9894 - recall: 0.9675\n",
      "Epoch 54: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0631 - accuracy: 0.9787 - precision: 0.9895 - recall: 0.9676 - val_loss: 0.0823 - val_accuracy: 0.9745 - val_precision: 0.9843 - val_recall: 0.9643 - lr: 2.5000e-04\n",
      "Epoch 55/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0346 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9697\n",
      "Epoch 54: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0631 - accuracy: 0.9787 - precision: 0.9895 - recall: 0.9676 - val_loss: 0.0823 - val_accuracy: 0.9745 - val_precision: 0.9843 - val_recall: 0.9643 - lr: 2.5000e-04\n",
      "Epoch 55/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9779 - precision: 0.9881 - recall: 0.9675\n",
      "Epoch 55: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0643 - accuracy: 0.9780 - precision: 0.9882 - recall: 0.9675 - val_loss: 0.0839 - val_accuracy: 0.9740 - val_precision: 0.9843 - val_recall: 0.9633 - lr: 2.5000e-04\n",
      "Epoch 56/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0386 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9677\n",
      "Epoch 55: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0643 - accuracy: 0.9780 - precision: 0.9882 - recall: 0.9675 - val_loss: 0.0839 - val_accuracy: 0.9740 - val_precision: 0.9843 - val_recall: 0.9633 - lr: 2.5000e-04\n",
      "Epoch 56/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9794 - precision: 0.9904 - recall: 0.9683\n",
      "Epoch 56: val_loss did not improve from 0.08149\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0631 - accuracy: 0.9793 - precision: 0.9905 - recall: 0.9680 - val_loss: 0.0821 - val_accuracy: 0.9752 - val_precision: 0.9854 - val_recall: 0.9647 - lr: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.08149\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0631 - accuracy: 0.9793 - precision: 0.9905 - recall: 0.9680 - val_loss: 0.0821 - val_accuracy: 0.9752 - val_precision: 0.9854 - val_recall: 0.9647 - lr: 2.5000e-04\n",
      "Epoch 57/100\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0615 - accuracy: 0.9783 - precision: 0.9901 - recall: 0.9663\n",
      "Epoch 57: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0613 - accuracy: 0.9784 - precision: 0.9903 - recall: 0.9663 - val_loss: 0.0825 - val_accuracy: 0.9748 - val_precision: 0.9850 - val_recall: 0.9643 - lr: 1.2500e-04\n",
      "Epoch 58/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.2611 - accuracy: 0.9219 - precision: 0.8519 - recall: 0.9583\n",
      "Epoch 57: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0613 - accuracy: 0.9784 - precision: 0.9903 - recall: 0.9663 - val_loss: 0.0825 - val_accuracy: 0.9748 - val_precision: 0.9850 - val_recall: 0.9643 - lr: 1.2500e-04\n",
      "Epoch 58/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9796 - precision: 0.9907 - recall: 0.9682\n",
      "Epoch 58: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0603 - accuracy: 0.9796 - precision: 0.9906 - recall: 0.9683 - val_loss: 0.0837 - val_accuracy: 0.9745 - val_precision: 0.9843 - val_recall: 0.9643 - lr: 1.2500e-04\n",
      "Epoch 59/100\n",
      "  1/375 [..............................] - ETA: 3s - loss: 0.0708 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9714\n",
      "Epoch 58: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0603 - accuracy: 0.9796 - precision: 0.9906 - recall: 0.9683 - val_loss: 0.0837 - val_accuracy: 0.9745 - val_precision: 0.9843 - val_recall: 0.9643 - lr: 1.2500e-04\n",
      "Epoch 59/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9797 - precision: 0.9903 - recall: 0.9688\n",
      "Epoch 59: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0604 - accuracy: 0.9796 - precision: 0.9903 - recall: 0.9688 - val_loss: 0.0837 - val_accuracy: 0.9743 - val_precision: 0.9840 - val_recall: 0.9643 - lr: 1.2500e-04\n",
      "Epoch 60/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0401 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9697\n",
      "Epoch 59: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0604 - accuracy: 0.9796 - precision: 0.9903 - recall: 0.9688 - val_loss: 0.0837 - val_accuracy: 0.9743 - val_precision: 0.9840 - val_recall: 0.9643 - lr: 1.2500e-04\n",
      "Epoch 60/100\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9801 - precision: 0.9912 - recall: 0.9687\n",
      "Epoch 60: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0594 - accuracy: 0.9800 - precision: 0.9911 - recall: 0.9687 - val_loss: 0.0842 - val_accuracy: 0.9750 - val_precision: 0.9847 - val_recall: 0.9650 - lr: 1.2500e-04\n",
      "Epoch 61/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0236 - accuracy: 0.9844 - precision: 0.9688 - recall: 1.0000\n",
      "Epoch 60: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0594 - accuracy: 0.9800 - precision: 0.9911 - recall: 0.9687 - val_loss: 0.0842 - val_accuracy: 0.9750 - val_precision: 0.9847 - val_recall: 0.9650 - lr: 1.2500e-04\n",
      "Epoch 61/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0607 - accuracy: 0.9789 - precision: 0.9907 - recall: 0.9668\n",
      "Epoch 61: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0601 - accuracy: 0.9791 - precision: 0.9908 - recall: 0.9672 - val_loss: 0.0838 - val_accuracy: 0.9747 - val_precision: 0.9834 - val_recall: 0.9657 - lr: 1.2500e-04\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0601 - accuracy: 0.9791 - precision: 0.9908 - recall: 0.9672 - val_loss: 0.0838 - val_accuracy: 0.9747 - val_precision: 0.9834 - val_recall: 0.9657 - lr: 1.2500e-04\n",
      "Epoch 62/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.9804 - precision: 0.9910 - recall: 0.9696\n",
      "Epoch 62: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0574 - accuracy: 0.9804 - precision: 0.9911 - recall: 0.9696 - val_loss: 0.0854 - val_accuracy: 0.9743 - val_precision: 0.9820 - val_recall: 0.9663 - lr: 1.2500e-04\n",
      "Epoch 63/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0576 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9722\n",
      "Epoch 62: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0574 - accuracy: 0.9804 - precision: 0.9911 - recall: 0.9696 - val_loss: 0.0854 - val_accuracy: 0.9743 - val_precision: 0.9820 - val_recall: 0.9663 - lr: 1.2500e-04\n",
      "Epoch 63/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9797 - precision: 0.9906 - recall: 0.9685\n",
      "Epoch 63: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0597 - accuracy: 0.9797 - precision: 0.9905 - recall: 0.9686 - val_loss: 0.0845 - val_accuracy: 0.9747 - val_precision: 0.9844 - val_recall: 0.9647 - lr: 1.2500e-04\n",
      "Epoch 64/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0541 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9706\n",
      "Epoch 63: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0597 - accuracy: 0.9797 - precision: 0.9905 - recall: 0.9686 - val_loss: 0.0845 - val_accuracy: 0.9747 - val_precision: 0.9844 - val_recall: 0.9647 - lr: 1.2500e-04\n",
      "Epoch 64/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9791 - precision: 0.9902 - recall: 0.9679\n",
      "Epoch 64: val_loss did not improve from 0.08149\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0618 - accuracy: 0.9792 - precision: 0.9901 - recall: 0.9681 - val_loss: 0.0829 - val_accuracy: 0.9745 - val_precision: 0.9834 - val_recall: 0.9653 - lr: 1.2500e-04\n",
      "Epoch 65/100\n",
      "  1/375 [..............................] - ETA: 3s - loss: 0.0342 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 64: val_loss did not improve from 0.08149\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0618 - accuracy: 0.9792 - precision: 0.9901 - recall: 0.9681 - val_loss: 0.0829 - val_accuracy: 0.9745 - val_precision: 0.9834 - val_recall: 0.9653 - lr: 1.2500e-04\n",
      "Epoch 65/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9792 - precision: 0.9905 - recall: 0.9677\n",
      "Epoch 65: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0576 - accuracy: 0.9793 - precision: 0.9905 - recall: 0.9678 - val_loss: 0.0840 - val_accuracy: 0.9748 - val_precision: 0.9840 - val_recall: 0.9653 - lr: 6.2500e-05\n",
      "Epoch 66/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.0304 - accuracy: 0.9844 - precision: 0.9630 - recall: 1.0000\n",
      "Epoch 65: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0576 - accuracy: 0.9793 - precision: 0.9905 - recall: 0.9678 - val_loss: 0.0840 - val_accuracy: 0.9748 - val_precision: 0.9840 - val_recall: 0.9653 - lr: 6.2500e-05\n",
      "Epoch 66/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0598 - accuracy: 0.9795 - precision: 0.9906 - recall: 0.9683\n",
      "Epoch 66: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0595 - accuracy: 0.9797 - precision: 0.9907 - recall: 0.9685 - val_loss: 0.0843 - val_accuracy: 0.9748 - val_precision: 0.9840 - val_recall: 0.9653 - lr: 6.2500e-05\n",
      "Epoch 67/100\n",
      " 31/375 [=>............................] - ETA: 1s - loss: 0.0566 - accuracy: 0.9819 - precision: 0.9882 - recall: 0.9736\n",
      "Epoch 66: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0595 - accuracy: 0.9797 - precision: 0.9907 - recall: 0.9685 - val_loss: 0.0843 - val_accuracy: 0.9748 - val_precision: 0.9840 - val_recall: 0.9653 - lr: 6.2500e-05\n",
      "Epoch 67/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9796 - precision: 0.9907 - recall: 0.9683Restoring model weights from the end of the best epoch: 52.\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0591 - accuracy: 0.9797 - precision: 0.9907 - recall: 0.9684 - val_loss: 0.0837 - val_accuracy: 0.9747 - val_precision: 0.9834 - val_recall: 0.9657 - lr: 6.2500e-05\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.08149\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0591 - accuracy: 0.9797 - precision: 0.9907 - recall: 0.9684 - val_loss: 0.0837 - val_accuracy: 0.9747 - val_precision: 0.9834 - val_recall: 0.9657 - lr: 6.2500e-05\n",
      "Epoch 67: early stopping\n",
      "âœ… Dense Model - Accuracy: 0.9740, Precision: 0.9824, Recall: 0.9653, F1: 0.9738\n",
      "\n",
      "ðŸ—ï¸  Training Advanced Conv1D Model...\n",
      "Conv1D model created with 46,449 parameters\n",
      "Epoch 1/100\n",
      "âœ… Dense Model - Accuracy: 0.9740, Precision: 0.9824, Recall: 0.9653, F1: 0.9738\n",
      "\n",
      "ðŸ—ï¸  Training Advanced Conv1D Model...\n",
      "Conv1D model created with 46,449 parameters\n",
      "Epoch 1/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.5070 - accuracy: 0.7559 - precision: 0.7589 - recall: 0.7500\n",
      "Epoch 1: val_loss improved from inf to 0.41980, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.41980, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 5s 9ms/step - loss: 0.5058 - accuracy: 0.7569 - precision: 0.7602 - recall: 0.7505 - val_loss: 0.4198 - val_accuracy: 0.8115 - val_precision: 0.9624 - val_recall: 0.6483 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 5s 9ms/step - loss: 0.5058 - accuracy: 0.7569 - precision: 0.7602 - recall: 0.7505 - val_loss: 0.4198 - val_accuracy: 0.8115 - val_precision: 0.9624 - val_recall: 0.6483 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.8653 - precision: 0.8847 - recall: 0.8401\n",
      "Epoch 2: val_loss improved from 0.41980 to 0.21141, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.41980 to 0.21141, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3255 - accuracy: 0.8653 - precision: 0.8847 - recall: 0.8401 - val_loss: 0.2114 - val_accuracy: 0.9152 - val_precision: 0.9495 - val_recall: 0.8770 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3255 - accuracy: 0.8653 - precision: 0.8847 - recall: 0.8401 - val_loss: 0.2114 - val_accuracy: 0.9152 - val_precision: 0.9495 - val_recall: 0.8770 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.8929 - precision: 0.9175 - recall: 0.8633\n",
      "Epoch 3: val_loss improved from 0.21141 to 0.17697, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.21141 to 0.17697, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2650 - accuracy: 0.8929 - precision: 0.9175 - recall: 0.8633 - val_loss: 0.1770 - val_accuracy: 0.9332 - val_precision: 0.9597 - val_recall: 0.9043 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2650 - accuracy: 0.8929 - precision: 0.9175 - recall: 0.8633 - val_loss: 0.1770 - val_accuracy: 0.9332 - val_precision: 0.9597 - val_recall: 0.9043 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.2359 - accuracy: 0.9076 - precision: 0.9316 - recall: 0.8799\n",
      "Epoch 4: val_loss improved from 0.17697 to 0.16199, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.17697 to 0.16199, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2352 - accuracy: 0.9081 - precision: 0.9321 - recall: 0.8803 - val_loss: 0.1620 - val_accuracy: 0.9408 - val_precision: 0.9645 - val_recall: 0.9153 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2352 - accuracy: 0.9081 - precision: 0.9321 - recall: 0.8803 - val_loss: 0.1620 - val_accuracy: 0.9408 - val_precision: 0.9645 - val_recall: 0.9153 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.2129 - accuracy: 0.9171 - precision: 0.9416 - recall: 0.8895\n",
      "Epoch 5: val_loss improved from 0.16199 to 0.15041, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.16199 to 0.15041, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2130 - accuracy: 0.9172 - precision: 0.9415 - recall: 0.8897 - val_loss: 0.1504 - val_accuracy: 0.9420 - val_precision: 0.9773 - val_recall: 0.9050 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2130 - accuracy: 0.9172 - precision: 0.9415 - recall: 0.8897 - val_loss: 0.1504 - val_accuracy: 0.9420 - val_precision: 0.9773 - val_recall: 0.9050 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9239 - precision: 0.9497 - recall: 0.8954\n",
      "Epoch 6: val_loss improved from 0.15041 to 0.14232, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.15041 to 0.14232, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1968 - accuracy: 0.9240 - precision: 0.9496 - recall: 0.8955 - val_loss: 0.1423 - val_accuracy: 0.9468 - val_precision: 0.9796 - val_recall: 0.9127 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1968 - accuracy: 0.9240 - precision: 0.9496 - recall: 0.8955 - val_loss: 0.1423 - val_accuracy: 0.9468 - val_precision: 0.9796 - val_recall: 0.9127 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9287 - precision: 0.9533 - recall: 0.9015\n",
      "Epoch 7: val_loss improved from 0.14232 to 0.13309, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.14232 to 0.13309, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1883 - accuracy: 0.9289 - precision: 0.9536 - recall: 0.9017 - val_loss: 0.1331 - val_accuracy: 0.9512 - val_precision: 0.9791 - val_recall: 0.9220 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1883 - accuracy: 0.9289 - precision: 0.9536 - recall: 0.9017 - val_loss: 0.1331 - val_accuracy: 0.9512 - val_precision: 0.9791 - val_recall: 0.9220 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.1736 - accuracy: 0.9330 - precision: 0.9588 - recall: 0.9050\n",
      "Epoch 8: val_loss did not improve from 0.13309\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1736 - accuracy: 0.9330 - precision: 0.9589 - recall: 0.9049 - val_loss: 0.1341 - val_accuracy: 0.9498 - val_precision: 0.9801 - val_recall: 0.9183 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "  1/375 [..............................] - ETA: 2s - loss: 0.3041 - accuracy: 0.8594 - precision: 0.8667 - recall: 0.8387\n",
      "Epoch 8: val_loss did not improve from 0.13309\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1736 - accuracy: 0.9330 - precision: 0.9589 - recall: 0.9049 - val_loss: 0.1341 - val_accuracy: 0.9498 - val_precision: 0.9801 - val_recall: 0.9183 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9370 - precision: 0.9616 - recall: 0.9104\n",
      "Epoch 9: val_loss improved from 0.13309 to 0.12632, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.13309 to 0.12632, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1710 - accuracy: 0.9370 - precision: 0.9614 - recall: 0.9107 - val_loss: 0.1263 - val_accuracy: 0.9557 - val_precision: 0.9753 - val_recall: 0.9350 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1710 - accuracy: 0.9370 - precision: 0.9614 - recall: 0.9107 - val_loss: 0.1263 - val_accuracy: 0.9557 - val_precision: 0.9753 - val_recall: 0.9350 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1610 - accuracy: 0.9412 - precision: 0.9641 - recall: 0.9166\n",
      "Epoch 10: val_loss improved from 0.12632 to 0.12328, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.12632 to 0.12328, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1610 - accuracy: 0.9411 - precision: 0.9637 - recall: 0.9168 - val_loss: 0.1233 - val_accuracy: 0.9550 - val_precision: 0.9840 - val_recall: 0.9250 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1610 - accuracy: 0.9411 - precision: 0.9637 - recall: 0.9168 - val_loss: 0.1233 - val_accuracy: 0.9550 - val_precision: 0.9840 - val_recall: 0.9250 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.1577 - accuracy: 0.9411 - precision: 0.9614 - recall: 0.9192\n",
      "Epoch 11: val_loss improved from 0.12328 to 0.11920, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.12328 to 0.11920, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1574 - accuracy: 0.9413 - precision: 0.9616 - recall: 0.9192 - val_loss: 0.1192 - val_accuracy: 0.9560 - val_precision: 0.9780 - val_recall: 0.9330 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1574 - accuracy: 0.9413 - precision: 0.9616 - recall: 0.9192 - val_loss: 0.1192 - val_accuracy: 0.9560 - val_precision: 0.9780 - val_recall: 0.9330 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9440 - precision: 0.9648 - recall: 0.9216\n",
      "Epoch 12: val_loss did not improve from 0.11920\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1506 - accuracy: 0.9439 - precision: 0.9647 - recall: 0.9215 - val_loss: 0.1204 - val_accuracy: 0.9538 - val_precision: 0.9706 - val_recall: 0.9360 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "  1/375 [..............................] - ETA: 3s - loss: 0.0976 - accuracy: 0.9688 - precision: 0.9667 - recall: 0.9667\n",
      "Epoch 12: val_loss did not improve from 0.11920\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1506 - accuracy: 0.9439 - precision: 0.9647 - recall: 0.9215 - val_loss: 0.1204 - val_accuracy: 0.9538 - val_precision: 0.9706 - val_recall: 0.9360 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9474 - precision: 0.9668 - recall: 0.9266\n",
      "Epoch 13: val_loss improved from 0.11920 to 0.11658, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.11920 to 0.11658, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1443 - accuracy: 0.9475 - precision: 0.9670 - recall: 0.9266 - val_loss: 0.1166 - val_accuracy: 0.9568 - val_precision: 0.9731 - val_recall: 0.9397 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1443 - accuracy: 0.9475 - precision: 0.9670 - recall: 0.9266 - val_loss: 0.1166 - val_accuracy: 0.9568 - val_precision: 0.9731 - val_recall: 0.9397 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 0.9499 - precision: 0.9672 - recall: 0.9314\n",
      "Epoch 14: val_loss improved from 0.11658 to 0.10897, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.11658 to 0.10897, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1395 - accuracy: 0.9500 - precision: 0.9673 - recall: 0.9314 - val_loss: 0.1090 - val_accuracy: 0.9603 - val_precision: 0.9825 - val_recall: 0.9373 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1395 - accuracy: 0.9500 - precision: 0.9673 - recall: 0.9314 - val_loss: 0.1090 - val_accuracy: 0.9603 - val_precision: 0.9825 - val_recall: 0.9373 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "185/375 [=============>................] - ETA: 1s - loss: 0.1338 - accuracy: 0.9500 - precision: 0.9681 - recall: 0.9303\n",
      "Epoch 26: val_loss did not improve from 0.09840\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1154 - accuracy: 0.9591 - precision: 0.9749 - recall: 0.9424 - val_loss: 0.1006 - val_accuracy: 0.9650 - val_precision: 0.9857 - val_recall: 0.9437 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1105 - accuracy: 0.9611 - precision: 0.9784 - recall: 0.9430\n",
      "Epoch 27: val_loss did not improve from 0.09840\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1107 - accuracy: 0.9609 - precision: 0.9783 - recall: 0.9427 - val_loss: 0.1031 - val_accuracy: 0.9632 - val_precision: 0.9793 - val_recall: 0.9463 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.9584 - precision: 0.9733 - recall: 0.9425\n",
      "Epoch 28: val_loss improved from 0.09840 to 0.09671, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1113 - accuracy: 0.9584 - precision: 0.9736 - recall: 0.9424 - val_loss: 0.0967 - val_accuracy: 0.9668 - val_precision: 0.9848 - val_recall: 0.9483 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1066 - accuracy: 0.9615 - precision: 0.9782 - recall: 0.9440\n",
      "Epoch 29: val_loss did not improve from 0.09671\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1065 - accuracy: 0.9615 - precision: 0.9783 - recall: 0.9440 - val_loss: 0.0982 - val_accuracy: 0.9648 - val_precision: 0.9878 - val_recall: 0.9413 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1091 - accuracy: 0.9607 - precision: 0.9779 - recall: 0.9427\n",
      "Epoch 30: val_loss improved from 0.09671 to 0.09254, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1089 - accuracy: 0.9608 - precision: 0.9781 - recall: 0.9427 - val_loss: 0.0925 - val_accuracy: 0.9683 - val_precision: 0.9845 - val_recall: 0.9517 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.9630 - precision: 0.9781 - recall: 0.9473\n",
      "Epoch 31: val_loss did not improve from 0.09254\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.1052 - accuracy: 0.9630 - precision: 0.9779 - recall: 0.9474 - val_loss: 0.0983 - val_accuracy: 0.9657 - val_precision: 0.9888 - val_recall: 0.9420 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9628 - precision: 0.9785 - recall: 0.9464\n",
      "Epoch 32: val_loss did not improve from 0.09254\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.1054 - accuracy: 0.9628 - precision: 0.9785 - recall: 0.9464 - val_loss: 0.0967 - val_accuracy: 0.9662 - val_precision: 0.9807 - val_recall: 0.9510 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.9640 - precision: 0.9799 - recall: 0.9474\n",
      "Epoch 33: val_loss did not improve from 0.09254\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1048 - accuracy: 0.9639 - precision: 0.9796 - recall: 0.9476 - val_loss: 0.0985 - val_accuracy: 0.9643 - val_precision: 0.9800 - val_recall: 0.9480 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9620 - precision: 0.9780 - recall: 0.9453\n",
      "Epoch 34: val_loss did not improve from 0.09254\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1072 - accuracy: 0.9620 - precision: 0.9780 - recall: 0.9453 - val_loss: 0.0969 - val_accuracy: 0.9668 - val_precision: 0.9844 - val_recall: 0.9487 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1040 - accuracy: 0.9633 - precision: 0.9796 - recall: 0.9462\n",
      "Epoch 35: val_loss did not improve from 0.09254\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1041 - accuracy: 0.9633 - precision: 0.9796 - recall: 0.9463 - val_loss: 0.0938 - val_accuracy: 0.9680 - val_precision: 0.9861 - val_recall: 0.9493 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9645 - precision: 0.9795 - recall: 0.9488\n",
      "Epoch 36: val_loss did not improve from 0.09254\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1018 - accuracy: 0.9645 - precision: 0.9796 - recall: 0.9488 - val_loss: 0.0951 - val_accuracy: 0.9668 - val_precision: 0.9765 - val_recall: 0.9567 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9632 - precision: 0.9776 - recall: 0.9483\n",
      "Epoch 37: val_loss improved from 0.09254 to 0.08960, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1006 - accuracy: 0.9632 - precision: 0.9775 - recall: 0.9483 - val_loss: 0.0896 - val_accuracy: 0.9702 - val_precision: 0.9882 - val_recall: 0.9517 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.1011 - accuracy: 0.9639 - precision: 0.9791 - recall: 0.9478\n",
      "Epoch 38: val_loss did not improve from 0.08960\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1011 - accuracy: 0.9637 - precision: 0.9793 - recall: 0.9474 - val_loss: 0.0918 - val_accuracy: 0.9672 - val_precision: 0.9798 - val_recall: 0.9540 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 0.9634 - precision: 0.9778 - recall: 0.9484\n",
      "Epoch 39: val_loss did not improve from 0.08960\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0993 - accuracy: 0.9635 - precision: 0.9778 - recall: 0.9486 - val_loss: 0.0916 - val_accuracy: 0.9680 - val_precision: 0.9841 - val_recall: 0.9513 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9667 - precision: 0.9810 - recall: 0.9518\n",
      "Epoch 40: val_loss did not improve from 0.08960\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0938 - accuracy: 0.9669 - precision: 0.9813 - recall: 0.9520 - val_loss: 0.0942 - val_accuracy: 0.9667 - val_precision: 0.9828 - val_recall: 0.9500 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9658 - precision: 0.9815 - recall: 0.9494\n",
      "Epoch 41: val_loss did not improve from 0.08960\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0991 - accuracy: 0.9658 - precision: 0.9816 - recall: 0.9494 - val_loss: 0.0904 - val_accuracy: 0.9685 - val_precision: 0.9842 - val_recall: 0.9523 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9648 - precision: 0.9799 - recall: 0.9491\n",
      "Epoch 42: val_loss improved from 0.08960 to 0.08696, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0987 - accuracy: 0.9647 - precision: 0.9799 - recall: 0.9488 - val_loss: 0.0870 - val_accuracy: 0.9705 - val_precision: 0.9862 - val_recall: 0.9543 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9656 - precision: 0.9811 - recall: 0.9496\n",
      "Epoch 43: val_loss did not improve from 0.08696\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0959 - accuracy: 0.9656 - precision: 0.9811 - recall: 0.9496 - val_loss: 0.0899 - val_accuracy: 0.9690 - val_precision: 0.9858 - val_recall: 0.9517 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9658 - precision: 0.9799 - recall: 0.9511\n",
      "Epoch 44: val_loss did not improve from 0.08696\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0969 - accuracy: 0.9657 - precision: 0.9797 - recall: 0.9513 - val_loss: 0.0903 - val_accuracy: 0.9683 - val_precision: 0.9852 - val_recall: 0.9510 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9663 - precision: 0.9810 - recall: 0.9510\n",
      "Epoch 45: val_loss did not improve from 0.08696\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0962 - accuracy: 0.9663 - precision: 0.9810 - recall: 0.9510 - val_loss: 0.0883 - val_accuracy: 0.9683 - val_precision: 0.9875 - val_recall: 0.9487 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9664 - precision: 0.9813 - recall: 0.9510\n",
      "Epoch 46: val_loss did not improve from 0.08696\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0947 - accuracy: 0.9664 - precision: 0.9813 - recall: 0.9510 - val_loss: 0.0887 - val_accuracy: 0.9683 - val_precision: 0.9848 - val_recall: 0.9513 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9654 - precision: 0.9806 - recall: 0.9496\n",
      "Epoch 47: val_loss did not improve from 0.08696\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0978 - accuracy: 0.9655 - precision: 0.9808 - recall: 0.9497 - val_loss: 0.0886 - val_accuracy: 0.9700 - val_precision: 0.9865 - val_recall: 0.9530 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9675 - precision: 0.9809 - recall: 0.9535\n",
      "Epoch 48: val_loss did not improve from 0.08696\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0929 - accuracy: 0.9676 - precision: 0.9811 - recall: 0.9536 - val_loss: 0.0896 - val_accuracy: 0.9693 - val_precision: 0.9835 - val_recall: 0.9547 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9680 - precision: 0.9817 - recall: 0.9537\n",
      "Epoch 49: val_loss did not improve from 0.08696\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0914 - accuracy: 0.9680 - precision: 0.9819 - recall: 0.9537 - val_loss: 0.0875 - val_accuracy: 0.9695 - val_precision: 0.9822 - val_recall: 0.9563 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0900 - accuracy: 0.9681 - precision: 0.9824 - recall: 0.9533\n",
      "Epoch 50: val_loss did not improve from 0.08696\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0900 - accuracy: 0.9680 - precision: 0.9824 - recall: 0.9531 - val_loss: 0.0885 - val_accuracy: 0.9695 - val_precision: 0.9859 - val_recall: 0.9527 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0849 - accuracy: 0.9701 - precision: 0.9850 - recall: 0.9548\n",
      "Epoch 51: val_loss improved from 0.08696 to 0.08680, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0849 - accuracy: 0.9701 - precision: 0.9850 - recall: 0.9547 - val_loss: 0.0868 - val_accuracy: 0.9708 - val_precision: 0.9856 - val_recall: 0.9557 - lr: 5.0000e-04\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9707 - precision: 0.9830 - recall: 0.9579\n",
      "Epoch 52: val_loss did not improve from 0.08680\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0858 - accuracy: 0.9707 - precision: 0.9830 - recall: 0.9579 - val_loss: 0.0888 - val_accuracy: 0.9700 - val_precision: 0.9879 - val_recall: 0.9517 - lr: 5.0000e-04\n",
      "Epoch 53/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0846 - accuracy: 0.9708 - precision: 0.9849 - recall: 0.9563\n",
      "Epoch 53: val_loss did not improve from 0.08680\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0847 - accuracy: 0.9709 - precision: 0.9850 - recall: 0.9564 - val_loss: 0.0873 - val_accuracy: 0.9700 - val_precision: 0.9845 - val_recall: 0.9550 - lr: 5.0000e-04\n",
      "Epoch 54/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.9687 - precision: 0.9825 - recall: 0.9543\n",
      "Epoch 54: val_loss did not improve from 0.08680\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0849 - accuracy: 0.9686 - precision: 0.9827 - recall: 0.9541 - val_loss: 0.0880 - val_accuracy: 0.9702 - val_precision: 0.9839 - val_recall: 0.9560 - lr: 5.0000e-04\n",
      "Epoch 55/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9708 - precision: 0.9837 - recall: 0.9576\n",
      "Epoch 55: val_loss did not improve from 0.08680\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0833 - accuracy: 0.9707 - precision: 0.9834 - recall: 0.9576 - val_loss: 0.0872 - val_accuracy: 0.9707 - val_precision: 0.9852 - val_recall: 0.9557 - lr: 5.0000e-04\n",
      "Epoch 56/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9715 - precision: 0.9837 - recall: 0.9590\n",
      "Epoch 56: val_loss did not improve from 0.08680\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0807 - accuracy: 0.9717 - precision: 0.9838 - recall: 0.9592 - val_loss: 0.0894 - val_accuracy: 0.9692 - val_precision: 0.9858 - val_recall: 0.9520 - lr: 5.0000e-04\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9709 - precision: 0.9839 - recall: 0.9574\n",
      "Epoch 57: val_loss improved from 0.08680 to 0.08605, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0839 - accuracy: 0.9709 - precision: 0.9839 - recall: 0.9574 - val_loss: 0.0861 - val_accuracy: 0.9710 - val_precision: 0.9849 - val_recall: 0.9567 - lr: 5.0000e-04\n",
      "Epoch 58/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9734 - precision: 0.9862 - recall: 0.9602\n",
      "Epoch 58: val_loss did not improve from 0.08605\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0792 - accuracy: 0.9733 - precision: 0.9861 - recall: 0.9602 - val_loss: 0.0874 - val_accuracy: 0.9700 - val_precision: 0.9855 - val_recall: 0.9540 - lr: 5.0000e-04\n",
      "Epoch 59/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9710 - precision: 0.9846 - recall: 0.9570\n",
      "Epoch 59: val_loss did not improve from 0.08605\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0809 - accuracy: 0.9709 - precision: 0.9846 - recall: 0.9567 - val_loss: 0.0863 - val_accuracy: 0.9700 - val_precision: 0.9865 - val_recall: 0.9530 - lr: 5.0000e-04\n",
      "Epoch 60/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0776 - accuracy: 0.9737 - precision: 0.9874 - recall: 0.9597\n",
      "Epoch 60: val_loss did not improve from 0.08605\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0778 - accuracy: 0.9735 - precision: 0.9873 - recall: 0.9594 - val_loss: 0.0865 - val_accuracy: 0.9708 - val_precision: 0.9856 - val_recall: 0.9557 - lr: 5.0000e-04\n",
      "Epoch 61/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 0.9721 - precision: 0.9845 - recall: 0.9594\n",
      "Epoch 61: val_loss improved from 0.08605 to 0.08515, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0777 - accuracy: 0.9722 - precision: 0.9844 - recall: 0.9595 - val_loss: 0.0852 - val_accuracy: 0.9715 - val_precision: 0.9869 - val_recall: 0.9557 - lr: 5.0000e-04\n",
      "Epoch 62/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 0.9718 - precision: 0.9853 - recall: 0.9580\n",
      "Epoch 62: val_loss improved from 0.08515 to 0.08384, saving model to ../backend/models\\advanced_conv1d_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0808 - accuracy: 0.9716 - precision: 0.9850 - recall: 0.9578 - val_loss: 0.0838 - val_accuracy: 0.9697 - val_precision: 0.9862 - val_recall: 0.9527 - lr: 5.0000e-04\n",
      "Epoch 63/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9726 - precision: 0.9862 - recall: 0.9587\n",
      "Epoch 63: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0795 - accuracy: 0.9725 - precision: 0.9861 - recall: 0.9586 - val_loss: 0.0846 - val_accuracy: 0.9705 - val_precision: 0.9832 - val_recall: 0.9573 - lr: 5.0000e-04\n",
      "Epoch 64/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9720 - precision: 0.9849 - recall: 0.9586\n",
      "Epoch 64: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0797 - accuracy: 0.9720 - precision: 0.9850 - recall: 0.9586 - val_loss: 0.0854 - val_accuracy: 0.9712 - val_precision: 0.9872 - val_recall: 0.9547 - lr: 5.0000e-04\n",
      "Epoch 65/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.9711 - precision: 0.9832 - recall: 0.9585\n",
      "Epoch 65: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0798 - accuracy: 0.9712 - precision: 0.9832 - recall: 0.9587 - val_loss: 0.0857 - val_accuracy: 0.9715 - val_precision: 0.9859 - val_recall: 0.9567 - lr: 5.0000e-04\n",
      "Epoch 66/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 0.9716 - precision: 0.9831 - recall: 0.9596\n",
      "Epoch 66: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0789 - accuracy: 0.9716 - precision: 0.9832 - recall: 0.9597 - val_loss: 0.0865 - val_accuracy: 0.9703 - val_precision: 0.9855 - val_recall: 0.9547 - lr: 5.0000e-04\n",
      "Epoch 67/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 0.9723 - precision: 0.9858 - recall: 0.9585\n",
      "Epoch 67: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0773 - accuracy: 0.9725 - precision: 0.9859 - recall: 0.9587 - val_loss: 0.0860 - val_accuracy: 0.9703 - val_precision: 0.9822 - val_recall: 0.9580 - lr: 5.0000e-04\n",
      "Epoch 68/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.9716 - precision: 0.9842 - recall: 0.9584\n",
      "Epoch 68: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0797 - accuracy: 0.9717 - precision: 0.9844 - recall: 0.9586 - val_loss: 0.0865 - val_accuracy: 0.9703 - val_precision: 0.9869 - val_recall: 0.9533 - lr: 5.0000e-04\n",
      "Epoch 69/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9736 - precision: 0.9864 - recall: 0.9603\n",
      "Epoch 69: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0765 - accuracy: 0.9736 - precision: 0.9864 - recall: 0.9604 - val_loss: 0.0874 - val_accuracy: 0.9702 - val_precision: 0.9872 - val_recall: 0.9527 - lr: 5.0000e-04\n",
      "Epoch 70/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 0.9729 - precision: 0.9855 - recall: 0.9599\n",
      "Epoch 70: val_loss did not improve from 0.08384\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0774 - accuracy: 0.9728 - precision: 0.9854 - recall: 0.9598 - val_loss: 0.0849 - val_accuracy: 0.9720 - val_precision: 0.9839 - val_recall: 0.9597 - lr: 5.0000e-04\n",
      "Epoch 71/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.9736 - precision: 0.9853 - recall: 0.9616\n",
      "Epoch 71: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0736 - accuracy: 0.9737 - precision: 0.9853 - recall: 0.9618 - val_loss: 0.0845 - val_accuracy: 0.9700 - val_precision: 0.9842 - val_recall: 0.9553 - lr: 2.5000e-04\n",
      "Epoch 72/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9751 - precision: 0.9867 - recall: 0.9631\n",
      "Epoch 72: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0730 - accuracy: 0.9750 - precision: 0.9864 - recall: 0.9632 - val_loss: 0.0849 - val_accuracy: 0.9708 - val_precision: 0.9832 - val_recall: 0.9580 - lr: 2.5000e-04\n",
      "Epoch 73/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0747 - accuracy: 0.9740 - precision: 0.9860 - recall: 0.9616\n",
      "Epoch 73: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0746 - accuracy: 0.9740 - precision: 0.9861 - recall: 0.9616 - val_loss: 0.0859 - val_accuracy: 0.9705 - val_precision: 0.9856 - val_recall: 0.9550 - lr: 2.5000e-04\n",
      "Epoch 74/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 0.9750 - precision: 0.9863 - recall: 0.9633\n",
      "Epoch 74: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0751 - accuracy: 0.9749 - precision: 0.9863 - recall: 0.9632 - val_loss: 0.0845 - val_accuracy: 0.9703 - val_precision: 0.9829 - val_recall: 0.9573 - lr: 2.5000e-04\n",
      "Epoch 75/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9743 - precision: 0.9854 - recall: 0.9629\n",
      "Epoch 75: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0739 - accuracy: 0.9744 - precision: 0.9853 - recall: 0.9631 - val_loss: 0.0851 - val_accuracy: 0.9722 - val_precision: 0.9863 - val_recall: 0.9577 - lr: 2.5000e-04\n",
      "Epoch 76/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9743 - precision: 0.9870 - recall: 0.9613\n",
      "Epoch 76: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0718 - accuracy: 0.9742 - precision: 0.9869 - recall: 0.9612 - val_loss: 0.0856 - val_accuracy: 0.9710 - val_precision: 0.9842 - val_recall: 0.9573 - lr: 2.5000e-04\n",
      "Epoch 77/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9751 - precision: 0.9878 - recall: 0.9620Restoring model weights from the end of the best epoch: 62.\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.08384\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0721 - accuracy: 0.9752 - precision: 0.9879 - recall: 0.9621 - val_loss: 0.0857 - val_accuracy: 0.9717 - val_precision: 0.9836 - val_recall: 0.9593 - lr: 2.5000e-04\n",
      "Epoch 77: early stopping\n",
      "âœ… Conv1D Model - Accuracy: 0.9697, Precision: 0.9862, Recall: 0.9527, F1: 0.9691\n",
      "\n",
      "ðŸ—ï¸  Training Advanced LSTM Model...\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "LSTM model created with 34,689 parameters\n",
      "Epoch 1/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.6117 - precision: 0.6133 - recall: 0.6048\n",
      "Epoch 1: val_loss improved from inf to 0.64345, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 81s 207ms/step - loss: 0.6673 - accuracy: 0.6117 - precision: 0.6133 - recall: 0.6048 - val_loss: 0.6434 - val_accuracy: 0.6855 - val_precision: 0.6696 - val_recall: 0.7323 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.6713 - precision: 0.6708 - recall: 0.6727\n",
      "Epoch 2: val_loss did not improve from 0.64345\n",
      "375/375 [==============================] - 80s 212ms/step - loss: 0.6179 - accuracy: 0.6713 - precision: 0.6708 - recall: 0.6727 - val_loss: 0.6445 - val_accuracy: 0.6388 - val_precision: 0.7075 - val_recall: 0.4733 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.7043 - precision: 0.7030 - recall: 0.7075\n",
      "Epoch 3: val_loss improved from 0.64345 to 0.60295, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 94s 250ms/step - loss: 0.5883 - accuracy: 0.7043 - precision: 0.7030 - recall: 0.7075 - val_loss: 0.6029 - val_accuracy: 0.6853 - val_precision: 0.7603 - val_recall: 0.5413 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.7272 - precision: 0.7226 - recall: 0.7373\n",
      "Epoch 4: val_loss improved from 0.60295 to 0.51980, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 79s 210ms/step - loss: 0.5632 - accuracy: 0.7272 - precision: 0.7226 - recall: 0.7373 - val_loss: 0.5198 - val_accuracy: 0.7463 - val_precision: 0.7366 - val_recall: 0.7670 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.7456 - precision: 0.7450 - recall: 0.7468\n",
      "Epoch 5: val_loss improved from 0.51980 to 0.48807, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 80s 212ms/step - loss: 0.5391 - accuracy: 0.7456 - precision: 0.7450 - recall: 0.7468 - val_loss: 0.4881 - val_accuracy: 0.7775 - val_precision: 0.7789 - val_recall: 0.7750 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.7601 - precision: 0.7622 - recall: 0.7563\n",
      "Epoch 6: val_loss did not improve from 0.48807\n",
      "375/375 [==============================] - 77s 205ms/step - loss: 0.5185 - accuracy: 0.7601 - precision: 0.7622 - recall: 0.7563 - val_loss: 0.5213 - val_accuracy: 0.7603 - val_precision: 0.7581 - val_recall: 0.7647 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.7721 - precision: 0.7798 - recall: 0.7584\n",
      "Epoch 7: val_loss did not improve from 0.48807\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.5030 - accuracy: 0.7721 - precision: 0.7798 - recall: 0.7584 - val_loss: 0.4895 - val_accuracy: 0.7763 - val_precision: 0.8636 - val_recall: 0.6563 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.7845 - precision: 0.7995 - recall: 0.7595\n",
      "Epoch 8: val_loss improved from 0.48807 to 0.40855, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 76s 201ms/step - loss: 0.4801 - accuracy: 0.7845 - precision: 0.7995 - recall: 0.7595 - val_loss: 0.4085 - val_accuracy: 0.8173 - val_precision: 0.8415 - val_recall: 0.7820 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.7887 - precision: 0.8064 - recall: 0.7598\n",
      "Epoch 9: val_loss did not improve from 0.40855\n",
      "375/375 [==============================] - 79s 210ms/step - loss: 0.4705 - accuracy: 0.7887 - precision: 0.8064 - recall: 0.7598 - val_loss: 0.4096 - val_accuracy: 0.8173 - val_precision: 0.8077 - val_recall: 0.8330 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.7987 - precision: 0.8148 - recall: 0.7732\n",
      "Epoch 10: val_loss improved from 0.40855 to 0.38391, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 78s 207ms/step - loss: 0.4519 - accuracy: 0.7987 - precision: 0.8148 - recall: 0.7732 - val_loss: 0.3839 - val_accuracy: 0.8328 - val_precision: 0.8411 - val_recall: 0.8207 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.8061 - precision: 0.8251 - recall: 0.7769\n",
      "Epoch 11: val_loss did not improve from 0.38391\n",
      "375/375 [==============================] - 83s 221ms/step - loss: 0.4446 - accuracy: 0.8061 - precision: 0.8251 - recall: 0.7769 - val_loss: 0.3888 - val_accuracy: 0.8327 - val_precision: 0.8783 - val_recall: 0.7723 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8135 - precision: 0.8350 - recall: 0.7814\n",
      "Epoch 12: val_loss improved from 0.38391 to 0.35935, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 83s 222ms/step - loss: 0.4272 - accuracy: 0.8135 - precision: 0.8350 - recall: 0.7814 - val_loss: 0.3594 - val_accuracy: 0.8517 - val_precision: 0.8697 - val_recall: 0.8273 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.8201 - precision: 0.8400 - recall: 0.7909\n",
      "Epoch 13: val_loss did not improve from 0.35935\n",
      "375/375 [==============================] - 83s 222ms/step - loss: 0.4126 - accuracy: 0.8201 - precision: 0.8400 - recall: 0.7909 - val_loss: 0.3661 - val_accuracy: 0.8452 - val_precision: 0.8416 - val_recall: 0.8503 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.8257 - precision: 0.8476 - recall: 0.7943\n",
      "Epoch 14: val_loss improved from 0.35935 to 0.34516, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 82s 218ms/step - loss: 0.4053 - accuracy: 0.8257 - precision: 0.8476 - recall: 0.7943 - val_loss: 0.3452 - val_accuracy: 0.8515 - val_precision: 0.9029 - val_recall: 0.7877 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8289 - precision: 0.8528 - recall: 0.7951\n",
      "Epoch 15: val_loss improved from 0.34516 to 0.32160, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 83s 221ms/step - loss: 0.3974 - accuracy: 0.8289 - precision: 0.8528 - recall: 0.7951 - val_loss: 0.3216 - val_accuracy: 0.8680 - val_precision: 0.8828 - val_recall: 0.8487 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8300 - precision: 0.8557 - recall: 0.7939\n",
      "Epoch 16: val_loss did not improve from 0.32160\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 0.3946 - accuracy: 0.8300 - precision: 0.8557 - recall: 0.7939 - val_loss: 0.3279 - val_accuracy: 0.8577 - val_precision: 0.9025 - val_recall: 0.8020 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.8372 - precision: 0.8652 - recall: 0.7990\n",
      "Epoch 17: val_loss improved from 0.32160 to 0.31267, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 85s 226ms/step - loss: 0.3797 - accuracy: 0.8372 - precision: 0.8652 - recall: 0.7990 - val_loss: 0.3127 - val_accuracy: 0.8692 - val_precision: 0.8745 - val_recall: 0.8620 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3715 - accuracy: 0.8426 - precision: 0.8664 - recall: 0.8101\n",
      "Epoch 18: val_loss improved from 0.31267 to 0.29957, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 76s 204ms/step - loss: 0.3715 - accuracy: 0.8426 - precision: 0.8664 - recall: 0.8101 - val_loss: 0.2996 - val_accuracy: 0.8800 - val_precision: 0.9034 - val_recall: 0.8510 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.8450 - precision: 0.8678 - recall: 0.8139\n",
      "Epoch 19: val_loss did not improve from 0.29957\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.3670 - accuracy: 0.8450 - precision: 0.8678 - recall: 0.8139 - val_loss: 0.3001 - val_accuracy: 0.8795 - val_precision: 0.9240 - val_recall: 0.8270 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.8512 - precision: 0.8750 - recall: 0.8194\n",
      "Epoch 20: val_loss improved from 0.29957 to 0.28411, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 74s 198ms/step - loss: 0.3516 - accuracy: 0.8512 - precision: 0.8750 - recall: 0.8194 - val_loss: 0.2841 - val_accuracy: 0.8810 - val_precision: 0.9224 - val_recall: 0.8320 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.8528 - precision: 0.8778 - recall: 0.8198\n",
      "Epoch 21: val_loss improved from 0.28411 to 0.27940, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 115s 307ms/step - loss: 0.3492 - accuracy: 0.8528 - precision: 0.8778 - recall: 0.8198 - val_loss: 0.2794 - val_accuracy: 0.8840 - val_precision: 0.9226 - val_recall: 0.8383 - lr: 0.0010\n",
      "Epoch 22/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8533 - precision: 0.8754 - recall: 0.8239\n",
      "Epoch 22: val_loss did not improve from 0.27940\n",
      "375/375 [==============================] - 187s 498ms/step - loss: 0.3430 - accuracy: 0.8533 - precision: 0.8754 - recall: 0.8239 - val_loss: 0.2884 - val_accuracy: 0.8775 - val_precision: 0.8992 - val_recall: 0.8503 - lr: 0.0010\n",
      "Epoch 23/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.8610 - precision: 0.8830 - recall: 0.8322\n",
      "Epoch 23: val_loss improved from 0.27940 to 0.27192, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 148s 395ms/step - loss: 0.3362 - accuracy: 0.8610 - precision: 0.8830 - recall: 0.8322 - val_loss: 0.2719 - val_accuracy: 0.8878 - val_precision: 0.9386 - val_recall: 0.8300 - lr: 0.0010\n",
      "Epoch 24/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.8627 - precision: 0.8849 - recall: 0.8340\n",
      "Epoch 24: val_loss improved from 0.27192 to 0.25648, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 151s 402ms/step - loss: 0.3296 - accuracy: 0.8627 - precision: 0.8849 - recall: 0.8340 - val_loss: 0.2565 - val_accuracy: 0.8907 - val_precision: 0.9216 - val_recall: 0.8540 - lr: 0.0010\n",
      "Epoch 25/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3220 - accuracy: 0.8660 - precision: 0.8858 - recall: 0.8404\n",
      "Epoch 25: val_loss did not improve from 0.25648\n",
      "375/375 [==============================] - 143s 383ms/step - loss: 0.3220 - accuracy: 0.8660 - precision: 0.8858 - recall: 0.8404 - val_loss: 0.2623 - val_accuracy: 0.8935 - val_precision: 0.9313 - val_recall: 0.8497 - lr: 0.0010\n",
      "Epoch 26/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.8671 - precision: 0.8909 - recall: 0.8367\n",
      "Epoch 26: val_loss did not improve from 0.25648\n",
      "375/375 [==============================] - 119s 318ms/step - loss: 0.3163 - accuracy: 0.8671 - precision: 0.8909 - recall: 0.8367 - val_loss: 0.2712 - val_accuracy: 0.8925 - val_precision: 0.9283 - val_recall: 0.8507 - lr: 0.0010\n",
      "Epoch 27/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.8691 - precision: 0.8920 - recall: 0.8400\n",
      "Epoch 27: val_loss improved from 0.25648 to 0.25234, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 121s 322ms/step - loss: 0.3151 - accuracy: 0.8691 - precision: 0.8920 - recall: 0.8400 - val_loss: 0.2523 - val_accuracy: 0.8980 - val_precision: 0.9160 - val_recall: 0.8763 - lr: 0.0010\n",
      "Epoch 28/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.8745 - precision: 0.8924 - recall: 0.8518\n",
      "Epoch 28: val_loss improved from 0.25234 to 0.23433, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 135s 361ms/step - loss: 0.3046 - accuracy: 0.8745 - precision: 0.8924 - recall: 0.8518 - val_loss: 0.2343 - val_accuracy: 0.9065 - val_precision: 0.9283 - val_recall: 0.8810 - lr: 0.0010\n",
      "Epoch 29/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3016 - accuracy: 0.8767 - precision: 0.8968 - recall: 0.8514\n",
      "Epoch 29: val_loss improved from 0.23433 to 0.23245, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 79s 212ms/step - loss: 0.3016 - accuracy: 0.8767 - precision: 0.8968 - recall: 0.8514 - val_loss: 0.2324 - val_accuracy: 0.9072 - val_precision: 0.9284 - val_recall: 0.8823 - lr: 0.0010\n",
      "Epoch 30/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.8773 - precision: 0.9004 - recall: 0.8483\n",
      "Epoch 30: val_loss did not improve from 0.23245\n",
      "375/375 [==============================] - 78s 207ms/step - loss: 0.3028 - accuracy: 0.8773 - precision: 0.9004 - recall: 0.8483 - val_loss: 0.2550 - val_accuracy: 0.8993 - val_precision: 0.9045 - val_recall: 0.8930 - lr: 0.0010\n",
      "Epoch 31/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.8791 - precision: 0.9026 - recall: 0.8498\n",
      "Epoch 31: val_loss did not improve from 0.23245\n",
      "375/375 [==============================] - 74s 197ms/step - loss: 0.2963 - accuracy: 0.8791 - precision: 0.9026 - recall: 0.8498 - val_loss: 0.2384 - val_accuracy: 0.9017 - val_precision: 0.9328 - val_recall: 0.8657 - lr: 0.0010\n",
      "Epoch 32/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.8845 - precision: 0.9060 - recall: 0.8581\n",
      "Epoch 32: val_loss did not improve from 0.23245\n",
      "375/375 [==============================] - 69s 185ms/step - loss: 0.2877 - accuracy: 0.8845 - precision: 0.9060 - recall: 0.8581 - val_loss: 0.2352 - val_accuracy: 0.9030 - val_precision: 0.9538 - val_recall: 0.8470 - lr: 0.0010\n",
      "Epoch 33/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.8860 - precision: 0.9094 - recall: 0.8574\n",
      "Epoch 33: val_loss improved from 0.23245 to 0.22538, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 69s 184ms/step - loss: 0.2864 - accuracy: 0.8860 - precision: 0.9094 - recall: 0.8574 - val_loss: 0.2254 - val_accuracy: 0.9088 - val_precision: 0.9410 - val_recall: 0.8723 - lr: 0.0010\n",
      "Epoch 34/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.8864 - precision: 0.9058 - recall: 0.8625\n",
      "Epoch 34: val_loss did not improve from 0.22538\n",
      "375/375 [==============================] - 69s 183ms/step - loss: 0.2809 - accuracy: 0.8864 - precision: 0.9058 - recall: 0.8625 - val_loss: 0.2413 - val_accuracy: 0.8988 - val_precision: 0.9544 - val_recall: 0.8377 - lr: 0.0010\n",
      "Epoch 35/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.8905 - precision: 0.9105 - recall: 0.8660\n",
      "Epoch 35: val_loss did not improve from 0.22538\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.2745 - accuracy: 0.8905 - precision: 0.9105 - recall: 0.8660 - val_loss: 0.2290 - val_accuracy: 0.9097 - val_precision: 0.9392 - val_recall: 0.8760 - lr: 0.0010\n",
      "Epoch 36/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.8909 - precision: 0.9078 - recall: 0.8702\n",
      "Epoch 36: val_loss improved from 0.22538 to 0.21679, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 70s 188ms/step - loss: 0.2728 - accuracy: 0.8909 - precision: 0.9078 - recall: 0.8702 - val_loss: 0.2168 - val_accuracy: 0.9105 - val_precision: 0.9444 - val_recall: 0.8723 - lr: 0.0010\n",
      "Epoch 37/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.8900 - precision: 0.9126 - recall: 0.8627\n",
      "Epoch 37: val_loss improved from 0.21679 to 0.21230, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 72s 191ms/step - loss: 0.2696 - accuracy: 0.8900 - precision: 0.9126 - recall: 0.8627 - val_loss: 0.2123 - val_accuracy: 0.9145 - val_precision: 0.9580 - val_recall: 0.8670 - lr: 0.0010\n",
      "Epoch 38/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.8959 - precision: 0.9173 - recall: 0.8702\n",
      "Epoch 38: val_loss improved from 0.21230 to 0.20630, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 72s 192ms/step - loss: 0.2616 - accuracy: 0.8959 - precision: 0.9173 - recall: 0.8702 - val_loss: 0.2063 - val_accuracy: 0.9185 - val_precision: 0.9432 - val_recall: 0.8907 - lr: 0.0010\n",
      "Epoch 39/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.8972 - precision: 0.9171 - recall: 0.8734\n",
      "Epoch 39: val_loss improved from 0.20630 to 0.20093, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 72s 192ms/step - loss: 0.2602 - accuracy: 0.8972 - precision: 0.9171 - recall: 0.8734 - val_loss: 0.2009 - val_accuracy: 0.9202 - val_precision: 0.9437 - val_recall: 0.8937 - lr: 0.0010\n",
      "Epoch 40/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.8985 - precision: 0.9198 - recall: 0.8731\n",
      "Epoch 40: val_loss did not improve from 0.20093\n",
      "375/375 [==============================] - 72s 193ms/step - loss: 0.2581 - accuracy: 0.8985 - precision: 0.9198 - recall: 0.8731 - val_loss: 0.2062 - val_accuracy: 0.9197 - val_precision: 0.9562 - val_recall: 0.8797 - lr: 0.0010\n",
      "Epoch 41/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.8972 - precision: 0.9240 - recall: 0.8656\n",
      "Epoch 41: val_loss did not improve from 0.20093\n",
      "375/375 [==============================] - 585s 2s/step - loss: 0.2588 - accuracy: 0.8972 - precision: 0.9240 - recall: 0.8656 - val_loss: 0.2042 - val_accuracy: 0.9197 - val_precision: 0.9639 - val_recall: 0.8720 - lr: 0.0010\n",
      "Epoch 42/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2484 - accuracy: 0.9000 - precision: 0.9231 - recall: 0.8727\n",
      "Epoch 42: val_loss did not improve from 0.20093\n",
      "375/375 [==============================] - 81s 216ms/step - loss: 0.2484 - accuracy: 0.9000 - precision: 0.9231 - recall: 0.8727 - val_loss: 0.2109 - val_accuracy: 0.9178 - val_precision: 0.9641 - val_recall: 0.8680 - lr: 0.0010\n",
      "Epoch 43/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.9017 - precision: 0.9255 - recall: 0.8737\n",
      "Epoch 43: val_loss improved from 0.20093 to 0.19965, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 69s 185ms/step - loss: 0.2499 - accuracy: 0.9017 - precision: 0.9255 - recall: 0.8737 - val_loss: 0.1996 - val_accuracy: 0.9215 - val_precision: 0.9600 - val_recall: 0.8797 - lr: 0.0010\n",
      "Epoch 44/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.9027 - precision: 0.9257 - recall: 0.8756\n",
      "Epoch 44: val_loss did not improve from 0.19965\n",
      "375/375 [==============================] - 71s 189ms/step - loss: 0.2430 - accuracy: 0.9027 - precision: 0.9257 - recall: 0.8756 - val_loss: 0.2190 - val_accuracy: 0.9142 - val_precision: 0.9655 - val_recall: 0.8590 - lr: 0.0010\n",
      "Epoch 45/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.9039 - precision: 0.9255 - recall: 0.8785\n",
      "Epoch 45: val_loss improved from 0.19965 to 0.19077, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 70s 187ms/step - loss: 0.2413 - accuracy: 0.9039 - precision: 0.9255 - recall: 0.8785 - val_loss: 0.1908 - val_accuracy: 0.9243 - val_precision: 0.9592 - val_recall: 0.8863 - lr: 0.0010\n",
      "Epoch 46/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9048 - precision: 0.9307 - recall: 0.8748\n",
      "Epoch 46: val_loss improved from 0.19077 to 0.18725, saving model to ../backend/models\\advanced_lstm_model.h5\n",
      "375/375 [==============================] - 76s 202ms/step - loss: 0.2384 - accuracy: 0.9048 - precision: 0.9307 - recall: 0.8748 - val_loss: 0.1872 - val_accuracy: 0.9247 - val_precision: 0.9531 - val_recall: 0.8933 - lr: 0.0010\n",
      "Epoch 47/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.9071 - precision: 0.9303 - recall: 0.8801\n",
      "Epoch 47: val_loss did not improve from 0.18725\n",
      "375/375 [==============================] - 76s 204ms/step - loss: 0.2365 - accuracy: 0.9071 - precision: 0.9303 - recall: 0.8801 - val_loss: 0.1943 - val_accuracy: 0.9252 - val_precision: 0.9590 - val_recall: 0.8883 - lr: 0.0010\n",
      "Epoch 48/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.9082 - precision: 0.9298 - recall: 0.8830\n",
      "Epoch 48: val_loss did not improve from 0.18725\n",
      "375/375 [==============================] - 80s 213ms/step - loss: 0.2354 - accuracy: 0.9082 - precision: 0.9298 - recall: 0.8830 - val_loss: 0.1936 - val_accuracy: 0.9242 - val_precision: 0.9602 - val_recall: 0.8850 - lr: 0.0010\n",
      "Epoch 49/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.9068 - precision: 0.9266 - recall: 0.8836\n",
      "Epoch 49: val_loss did not improve from 0.18725\n",
      "375/375 [==============================] - 79s 211ms/step - loss: 0.2312 - accuracy: 0.9068 - precision: 0.9266 - recall: 0.8836 - val_loss: 0.1987 - val_accuracy: 0.9198 - val_precision: 0.9730 - val_recall: 0.8637 - lr: 0.0010\n",
      "Epoch 50/80\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.9085 - precision: 0.9302 - recall: 0.8834\n",
      "Epoch 50: val_loss did not improve from 0.18725\n",
      "375/375 [==============================] - 80s 212ms/step - loss: 0.2301 - accuracy: 0.9085 - precision: 0.9302 - recall: 0.8834 - val_loss: 0.1900 - val_accuracy: 0.9245 - val_precision: 0.9646 - val_recall: 0.8813 - lr: 0.0010\n",
      "Epoch 51/80\n",
      "168/375 [============>.................] - ETA: 40s - loss: 0.2268 - accuracy: 0.9094 - precision: 0.9270 - recall: 0.8857"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 96\u001b[0m\n\u001b[0;32m     93\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m create_lstm_model(features_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM model created with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_model\u001b[38;5;241m.\u001b[39mcount_params()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m lstm_history \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduced epochs for LSTM (slower to train)\u001b[39;49;00m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_lstm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m lstm_results \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    106\u001b[0m lstm_acc, lstm_prec, lstm_rec \u001b[38;5;241m=\u001b[39m lstm_results[\u001b[38;5;241m1\u001b[39m], lstm_results[\u001b[38;5;241m2\u001b[39m], lstm_results[\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\surya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\surya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\surya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\surya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\surya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\surya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\surya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\surya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\surya\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_scaled, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Convert labels to numpy arrays (FIX for TensorFlow compatibility)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "print(f\"\\nðŸ“Š Data Split:\")\n",
    "print(f\"  Training: {len(X_train)} samples\")\n",
    "print(f\"  Testing: {len(X_test)} samples\")\n",
    "print(f\"  Features: {features_scaled.shape[1]}\")\n",
    "print(f\"  Labels converted to numpy arrays: y_train.shape = {y_train.shape}, y_test.shape = {y_test.shape}\")\n",
    "\n",
    "# Enhanced callbacks with reduced epochs for faster training\n",
    "callbacks_dense = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('../backend/models/advanced_dense_model.h5', save_best_only=True, monitor='val_loss', verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "callbacks_conv = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('../backend/models/advanced_conv1d_model.h5', save_best_only=True, monitor='val_loss', verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "callbacks_lstm = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('../backend/models/advanced_lstm_model.h5', save_best_only=True, monitor='val_loss', verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "# Train models and store results with error handling\n",
    "model_results = {}\n",
    "training_histories = {}\n",
    "\n",
    "try:\n",
    "    print(\"\\nðŸ—ï¸  Training Advanced Dense Neural Network...\")\n",
    "    dense_model = create_advanced_dense_model(features_scaled.shape[1])\n",
    "    print(f\"Dense model created with {dense_model.count_params():,} parameters\")\n",
    "    \n",
    "    dense_history = dense_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,  # Reduced epochs for faster training\n",
    "        batch_size=64,  # Increased batch size for efficiency\n",
    "        callbacks=callbacks_dense,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    dense_results = dense_model.evaluate(X_test, y_test, verbose=0)\n",
    "    dense_acc, dense_prec, dense_rec = dense_results[1], dense_results[2], dense_results[3]\n",
    "    dense_f1 = 2 * (dense_prec * dense_rec) / (dense_prec + dense_rec) if (dense_prec + dense_rec) > 0 else 0\n",
    "    model_results['Advanced Dense NN'] = {'accuracy': dense_acc, 'precision': dense_prec, 'recall': dense_rec, 'f1': dense_f1}\n",
    "    training_histories['dense'] = dense_history\n",
    "    \n",
    "    print(f\"âœ… Dense Model - Accuracy: {dense_acc:.4f}, Precision: {dense_prec:.4f}, Recall: {dense_rec:.4f}, F1: {dense_f1:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error training Dense Model: {e}\")\n",
    "    dense_history = None\n",
    "\n",
    "try:\n",
    "    print(\"\\nðŸ—ï¸  Training Advanced Conv1D Model...\")\n",
    "    conv_model = create_advanced_conv1d_model(features_scaled.shape[1])\n",
    "    print(f\"Conv1D model created with {conv_model.count_params():,} parameters\")\n",
    "    \n",
    "    conv_history = conv_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks_conv,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    conv_results = conv_model.evaluate(X_test, y_test, verbose=0)\n",
    "    conv_acc, conv_prec, conv_rec = conv_results[1], conv_results[2], conv_results[3]\n",
    "    conv_f1 = 2 * (conv_prec * conv_rec) / (conv_prec + conv_rec) if (conv_prec + conv_rec) > 0 else 0\n",
    "    model_results['Advanced Conv1D'] = {'accuracy': conv_acc, 'precision': conv_prec, 'recall': conv_rec, 'f1': conv_f1}\n",
    "    training_histories['conv'] = conv_history\n",
    "    \n",
    "    print(f\"âœ… Conv1D Model - Accuracy: {conv_acc:.4f}, Precision: {conv_prec:.4f}, Recall: {conv_rec:.4f}, F1: {conv_f1:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error training Conv1D Model: {e}\")\n",
    "    conv_history = None\n",
    "\n",
    "try:\n",
    "    print(\"\\nðŸ—ï¸  Training Advanced LSTM Model...\")\n",
    "    lstm_model = create_lstm_model(features_scaled.shape[1])\n",
    "    print(f\"LSTM model created with {lstm_model.count_params():,} parameters\")\n",
    "    \n",
    "    lstm_history = lstm_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=80,  # Reduced epochs for LSTM (slower to train)\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks_lstm,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    lstm_results = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
    "    lstm_acc, lstm_prec, lstm_rec = lstm_results[1], lstm_results[2], lstm_results[3]\n",
    "    lstm_f1 = 2 * (lstm_prec * lstm_rec) / (lstm_prec + lstm_rec) if (lstm_prec + lstm_rec) > 0 else 0\n",
    "    model_results['Advanced LSTM'] = {'accuracy': lstm_acc, 'precision': lstm_prec, 'recall': lstm_rec, 'f1': lstm_f1}\n",
    "    training_histories['lstm'] = lstm_history\n",
    "    \n",
    "    print(f\"âœ… LSTM Model - Accuracy: {lstm_acc:.4f}, Precision: {lstm_prec:.4f}, Recall: {lstm_rec:.4f}, F1: {lstm_f1:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error training LSTM Model: {e}\")\n",
    "    lstm_history = None\n",
    "\n",
    "print(\"\\nðŸŒ² Training Random Forest Classifier...\")\n",
    "try:\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=200,  # Reduced for faster training\n",
    "        max_depth=20,      # Reduced to prevent overfitting\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "    rf_prec = precision_score(y_test, y_pred_rf)\n",
    "    rf_rec = recall_score(y_test, y_pred_rf)\n",
    "    rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "    model_results['Random Forest'] = {'accuracy': rf_acc, 'precision': rf_prec, 'recall': rf_rec, 'f1': rf_f1}\n",
    "    \n",
    "    with open(\"../backend/models/random_forest_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(rf_model, f)\n",
    "    \n",
    "    print(f\"âœ… Random Forest - Accuracy: {rf_acc:.4f}, Precision: {rf_prec:.4f}, Recall: {rf_rec:.4f}, F1: {rf_f1:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error training Random Forest: {e}\")\n",
    "\n",
    "print(\"\\nðŸš€ Training Gradient Boosting Classifier...\")\n",
    "try:\n",
    "    gb_model = GradientBoostingClassifier(\n",
    "        n_estimators=150,  # Reduced for faster training\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,       # Reduced to prevent overfitting\n",
    "        random_state=42\n",
    "    )\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_gb = gb_model.predict(X_test)\n",
    "    gb_acc = accuracy_score(y_test, y_pred_gb)\n",
    "    gb_prec = precision_score(y_test, y_pred_gb)\n",
    "    gb_rec = recall_score(y_test, y_pred_gb)\n",
    "    gb_f1 = f1_score(y_test, y_pred_gb)\n",
    "    model_results['Gradient Boosting'] = {'accuracy': gb_acc, 'precision': gb_prec, 'recall': gb_rec, 'f1': gb_f1}\n",
    "    \n",
    "    with open(\"../backend/models/gradient_boosting_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(gb_model, f)\n",
    "    \n",
    "    print(f\"âœ… Gradient Boosting - Accuracy: {gb_acc:.4f}, Precision: {gb_prec:.4f}, Recall: {gb_rec:.4f}, F1: {gb_f1:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error training Gradient Boosting: {e}\")\n",
    "\n",
    "print(\"\\nâš™ï¸  Training SVM Classifier...\")\n",
    "try:\n",
    "    svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "    svm_prec = precision_score(y_test, y_pred_svm)\n",
    "    svm_rec = recall_score(y_test, y_pred_svm)\n",
    "    svm_f1 = f1_score(y_test, y_pred_svm)\n",
    "    model_results['SVM (RBF)'] = {'accuracy': svm_acc, 'precision': svm_prec, 'recall': svm_rec, 'f1': svm_f1}\n",
    "    \n",
    "    with open(\"../backend/models/svm_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(svm_model, f)\n",
    "    \n",
    "    print(f\"âœ… SVM - Accuracy: {svm_acc:.4f}, Precision: {svm_prec:.4f}, Recall: {svm_rec:.4f}, F1: {svm_f1:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error training SVM: {e}\")\n",
    "\n",
    "# Print classification reports for successfully trained models\n",
    "if 'Random Forest' in model_results:\n",
    "    print(\"\\nðŸ“Š Detailed Classification Reports:\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"RANDOM FOREST CLASSIFICATION REPORT:\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "if 'Gradient Boosting' in model_results:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"GRADIENT BOOSTING CLASSIFICATION REPORT:\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "if 'SVM (RBF)' in model_results:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SVM CLASSIFICATION REPORT:\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Training completed! {len(model_results)} models trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7428d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Visualization and Analysis with error handling\n",
    "plt.style.use('default')\n",
    "\n",
    "# Check if we have any trained models\n",
    "if not model_results:\n",
    "    print(\"âŒ No models were trained successfully. Please run the training cell first.\")\n",
    "else:\n",
    "    # Create figure with appropriate size\n",
    "    n_plots = 4 if any('dense' in training_histories for _ in [True]) else 3\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Model Performance Comparison\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    model_names = list(model_results.keys())\n",
    "    x_pos = np.arange(len(model_names))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [model_results[model][metric] for model in model_names]\n",
    "        axes[0, 0].bar(x_pos + i*0.2, values, width=0.2, label=metric.capitalize(), alpha=0.8)\n",
    "    \n",
    "    axes[0, 0].set_xlabel('Models')\n",
    "    axes[0, 0].set_ylabel('Score')\n",
    "    axes[0, 0].set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xticks(x_pos + 0.3)\n",
    "    axes[0, 0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # 2. Training History - Accuracy (only for neural networks that completed training)\n",
    "    if training_histories:\n",
    "        has_nn_history = False\n",
    "        if 'dense' in training_histories and training_histories['dense'] is not None:\n",
    "            axes[0, 1].plot(training_histories['dense'].history['accuracy'], label='Dense Train', linewidth=2)\n",
    "            axes[0, 1].plot(training_histories['dense'].history['val_accuracy'], label='Dense Val', linewidth=2)\n",
    "            has_nn_history = True\n",
    "        if 'conv' in training_histories and training_histories['conv'] is not None:\n",
    "            axes[0, 1].plot(training_histories['conv'].history['accuracy'], label='Conv1D Train', linewidth=2)\n",
    "            axes[0, 1].plot(training_histories['conv'].history['val_accuracy'], label='Conv1D Val', linewidth=2)\n",
    "            has_nn_history = True\n",
    "        if 'lstm' in training_histories and training_histories['lstm'] is not None:\n",
    "            axes[0, 1].plot(training_histories['lstm'].history['accuracy'], label='LSTM Train', linewidth=2)\n",
    "            axes[0, 1].plot(training_histories['lstm'].history['val_accuracy'], label='LSTM Val', linewidth=2)\n",
    "            has_nn_history = True\n",
    "        \n",
    "        if has_nn_history:\n",
    "            axes[0, 1].set_title('Neural Network Training - Accuracy', fontsize=14, fontweight='bold')\n",
    "            axes[0, 1].set_xlabel('Epoch')\n",
    "            axes[0, 1].set_ylabel('Accuracy')\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, 'No Neural Network\\nTraining History\\nAvailable', \n",
    "                           ha='center', va='center', transform=axes[0, 1].transAxes,\n",
    "                           fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "            axes[0, 1].set_title('Neural Network Training - Accuracy', fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, 'No Training History\\nAvailable', \n",
    "                       ha='center', va='center', transform=axes[0, 1].transAxes,\n",
    "                       fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "        axes[0, 1].set_title('Neural Network Training - Accuracy', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. Training History - Loss\n",
    "    if training_histories:\n",
    "        has_nn_history = False\n",
    "        if 'dense' in training_histories and training_histories['dense'] is not None:\n",
    "            axes[0, 2].plot(training_histories['dense'].history['loss'], label='Dense Train', linewidth=2)\n",
    "            axes[0, 2].plot(training_histories['dense'].history['val_loss'], label='Dense Val', linewidth=2)\n",
    "            has_nn_history = True\n",
    "        if 'conv' in training_histories and training_histories['conv'] is not None:\n",
    "            axes[0, 2].plot(training_histories['conv'].history['loss'], label='Conv1D Train', linewidth=2)\n",
    "            axes[0, 2].plot(training_histories['conv'].history['val_loss'], label='Conv1D Val', linewidth=2)\n",
    "            has_nn_history = True\n",
    "        if 'lstm' in training_histories and training_histories['lstm'] is not None:\n",
    "            axes[0, 2].plot(training_histories['lstm'].history['loss'], label='LSTM Train', linewidth=2)\n",
    "            axes[0, 2].plot(training_histories['lstm'].history['val_loss'], label='LSTM Val', linewidth=2)\n",
    "            has_nn_history = True\n",
    "        \n",
    "        if has_nn_history:\n",
    "            axes[0, 2].set_title('Neural Network Training - Loss', fontsize=14, fontweight='bold')\n",
    "            axes[0, 2].set_xlabel('Epoch')\n",
    "            axes[0, 2].set_ylabel('Loss')\n",
    "            axes[0, 2].legend()\n",
    "            axes[0, 2].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[0, 2].text(0.5, 0.5, 'No Neural Network\\nTraining History\\nAvailable', \n",
    "                           ha='center', va='center', transform=axes[0, 2].transAxes,\n",
    "                           fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "            axes[0, 2].set_title('Neural Network Training - Loss', fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        axes[0, 2].text(0.5, 0.5, 'No Training History\\nAvailable', \n",
    "                       ha='center', va='center', transform=axes[0, 2].transAxes,\n",
    "                       fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "        axes[0, 2].set_title('Neural Network Training - Loss', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 4. Feature Importance (Random Forest if available)\n",
    "    if 'Random Forest' in model_results and 'rf_model' in locals():\n",
    "        feature_importance = rf_model.feature_importances_\n",
    "        top_indices = np.argsort(feature_importance)[-25:]\n",
    "        axes[1, 0].barh(range(25), feature_importance[top_indices], alpha=0.8, color='forestgreen')\n",
    "        axes[1, 0].set_title('Random Forest - Top 25 Feature Importance', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Importance')\n",
    "        axes[1, 0].set_ylabel('Feature Index')\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'Random Forest\\nNot Available\\nfor Feature Importance', \n",
    "                       ha='center', va='center', transform=axes[1, 0].transAxes,\n",
    "                       fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
    "        axes[1, 0].set_title('Random Forest - Feature Importance', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 5. Model Accuracy Heatmap\n",
    "    accuracy_matrix = np.array([[model_results[model]['accuracy'] for model in model_names]])\n",
    "    im = axes[1, 1].imshow(accuracy_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "    axes[1, 1].set_title('Model Accuracy Heatmap', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xticks(range(len(model_names)))\n",
    "    axes[1, 1].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    axes[1, 1].set_yticks([0])\n",
    "    axes[1, 1].set_yticklabels(['Accuracy'])\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i, model in enumerate(model_names):\n",
    "        axes[1, 1].text(i, 0, f'{model_results[model][\"accuracy\"]:.3f}', \n",
    "                       ha='center', va='center', fontweight='bold', color='black')\n",
    "    \n",
    "    plt.colorbar(im, ax=axes[1, 1])\n",
    "    \n",
    "    # 6. F1-Score Comparison\n",
    "    f1_scores = [model_results[model]['f1'] for model in model_names]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(model_names)))\n",
    "    bars = axes[1, 2].bar(model_names, f1_scores, color=colors, alpha=0.8)\n",
    "    axes[1, 2].set_title('F1-Score Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1, 2].set_ylabel('F1-Score')\n",
    "    axes[1, 2].set_ylim(0, 1)\n",
    "    axes[1, 2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, f1 in zip(bars, f1_scores):\n",
    "        axes[1, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                       f'{f1:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance Summary Table\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ðŸ† COMPREHENSIVE MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{'Model':<20} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    for model_name, metrics in model_results.items():\n",
    "        print(f\"{model_name:<20} {metrics['accuracy']:<12.4f} {metrics['precision']:<12.4f} \"\n",
    "              f\"{metrics['recall']:<12.4f} {metrics['f1']:<12.4f}\")\n",
    "    \n",
    "    # Find best models for each metric\n",
    "    if model_results:\n",
    "        best_accuracy = max(model_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "        best_precision = max(model_results.items(), key=lambda x: x[1]['precision'])\n",
    "        best_recall = max(model_results.items(), key=lambda x: x[1]['recall'])\n",
    "        best_f1 = max(model_results.items(), key=lambda x: x[1]['f1'])\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"ðŸ¥‡ BEST PERFORMING MODELS BY METRIC\")\n",
    "        print(\"=\"*100)\n",
    "        print(f\"ðŸŽ¯ Best Accuracy:  {best_accuracy[0]} ({best_accuracy[1]['accuracy']:.4f})\")\n",
    "        print(f\"ðŸŽ¯ Best Precision: {best_precision[0]} ({best_precision[1]['precision']:.4f})\")\n",
    "        print(f\"ðŸŽ¯ Best Recall:    {best_recall[0]} ({best_recall[1]['recall']:.4f})\")\n",
    "        print(f\"ðŸŽ¯ Best F1-Score:  {best_f1[0]} ({best_f1[1]['f1']:.4f})\")\n",
    "    \n",
    "    print(f\"\\nâœ… {len(model_results)} models trained and evaluated successfully!\")\n",
    "    print(\"ðŸ“ Model files saved in: ../backend/models/\")\n",
    "    print(\"ðŸ“Š Comprehensive feature extraction completed with enhanced biochemical properties\")\n",
    "    if 'features_scaled' in locals():\n",
    "        print(f\"ðŸ”¬ Total features per sequence: {features_scaled.shape[1]}\")\n",
    "    if 'sequences' in locals():\n",
    "        print(f\"ðŸ“ˆ Dataset size: {len(sequences):,} sequences\")\n",
    "    \n",
    "    # Model recommendations\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ðŸ’¡ MODEL RECOMMENDATIONS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    if model_results:\n",
    "        # Find models with balanced performance\n",
    "        balanced_scores = {}\n",
    "        for model_name, metrics in model_results.items():\n",
    "            # Calculate balanced score (harmonic mean of all metrics)\n",
    "            balanced_score = 4 / (1/metrics['accuracy'] + 1/metrics['precision'] + 1/metrics['recall'] + 1/metrics['f1'])\n",
    "            balanced_scores[model_name] = balanced_score\n",
    "        \n",
    "        best_balanced = max(balanced_scores.items(), key=lambda x: x[1])\n",
    "        \n",
    "        print(f\"ðŸŒŸ Most Balanced Model: {best_balanced[0]} (Harmonic Mean: {best_balanced[1]:.4f})\")\n",
    "        print(\"ðŸ” Use this model for general therapeutic peptide prediction\")\n",
    "        \n",
    "        # High precision model\n",
    "        high_precision = max(model_results.items(), key=lambda x: x[1]['precision'])\n",
    "        print(f\"ðŸŽ¯ High Precision Model: {high_precision[0]} (Precision: {high_precision[1]['precision']:.4f})\")\n",
    "        print(\"ðŸ” Use this model when you want to minimize false positives\")\n",
    "        \n",
    "        # High recall model  \n",
    "        high_recall = max(model_results.items(), key=lambda x: x[1]['recall'])\n",
    "        print(f\"ðŸ” High Recall Model: {high_recall[0]} (Recall: {high_recall[1]['recall']:.4f})\")\n",
    "        print(\"ðŸ” Use this model when you want to minimize false negatives\")\n",
    "        \n",
    "    print(\"\\nðŸš€ Analysis complete! All models ready for deployment.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
